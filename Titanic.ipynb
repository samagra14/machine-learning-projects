{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setting up this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to support python 2 and python 3\n",
    "from __future__ import division, print_function, unicode_literals\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "# to make this notebook's output stable across runs\n",
    "np.random.seed(42)\n",
    "\n",
    "# to make plots\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "HOUSING_PATH = \"datasets/titanic\"\n",
    "# getting a dataframe object from the csv file\n",
    "import pandas as pd\n",
    "def load_housing_data(path,housing_path=HOUSING_PATH):\n",
    "    csv_path = os.path.join(housing_path, path)\n",
    "    return pd.read_csv(csv_path)\n",
    "titanic = load_housing_data(path = \"train.csv\")\n",
    "titanic_test = load_housing_data(path = \"test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Moran, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330877</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>McCarthy, Mr. Timothy J</td>\n",
       "      <td>male</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17463</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>E46</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Master. Gosta Leonard</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Nasser, Mrs. Nicholas (Adele Achem)</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>237736</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Sandstrom, Miss. Marguerite Rut</td>\n",
       "      <td>female</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>PP 9549</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>G6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Bonnell, Miss. Elizabeth</td>\n",
       "      <td>female</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113783</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>C103</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Saundercock, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5. 2151</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Andersson, Mr. Anders Johan</td>\n",
       "      <td>male</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347082</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vestrom, Miss. Hulda Amanda Adolfina</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>350406</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Hewlett, Mrs. (Mary D Kingcome)</td>\n",
       "      <td>female</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248706</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Master. Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Planke, Mrs. Julius (Emelia Maria Vande...</td>\n",
       "      <td>female</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>345763</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Masselmani, Mrs. Fatima</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2649</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Fynney, Mr. Joseph J</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>239865</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Beesley, Mr. Lawrence</td>\n",
       "      <td>male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>248698</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>D56</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>McGowan, Miss. Anna \"Annie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330923</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Sloper, Mr. William Thompson</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113788</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>A6</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Palsson, Miss. Torborg Danira</td>\n",
       "      <td>female</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>349909</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>347077</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Emir, Mr. Farred Chehab</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2631</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Fortune, Mr. Charles Alexander</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>19950</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>C23 C25 C27</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>O'Dwyer, Miss. Ellen \"Nellie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330959</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Todoroff, Mr. Lalio</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349216</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>862</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Giles, Mr. Frederick Edward</td>\n",
       "      <td>male</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28134</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>863</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Swift, Mrs. Frederick Joel (Margaret Welles Ba...</td>\n",
       "      <td>female</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>17466</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>D17</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>864</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sage, Miss. Dorothy Edith \"Dolly\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>CA. 2343</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>865</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Gill, Mr. John William</td>\n",
       "      <td>male</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>233866</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>866</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Bystrom, Mrs. (Karolina)</td>\n",
       "      <td>female</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>236852</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>867</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Duran y More, Miss. Asuncion</td>\n",
       "      <td>female</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>SC/PARIS 2149</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>868</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Roebling, Mr. Washington Augustus II</td>\n",
       "      <td>male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17590</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>A24</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>869</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>van Melkebeke, Mr. Philemon</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345777</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>870</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnson, Master. Harold Theodor</td>\n",
       "      <td>male</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>347742</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>871</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Balkic, Mr. Cerin</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349248</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>872</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Beckwith, Mrs. Richard Leonard (Sallie Monypeny)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11751</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>D35</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Carlsson, Mr. Frans Olof</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>874</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Vander Cruyssen, Mr. Victor</td>\n",
       "      <td>male</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>345765</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>875</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Abelson, Mrs. Samuel (Hannah Wizosky)</td>\n",
       "      <td>female</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>P/PP 3381</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>876</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Najib, Miss. Adele Kiamie \"Jane\"</td>\n",
       "      <td>female</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2667</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>877</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Gustafsson, Mr. Alfred Ossian</td>\n",
       "      <td>male</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7534</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>878</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Petroff, Mr. Nedelio</td>\n",
       "      <td>male</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349212</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>879</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Laleff, Mr. Kristo</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349217</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>880</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)</td>\n",
       "      <td>female</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>11767</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C50</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>881</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Shelley, Mrs. William (Imanita Parrish Hall)</td>\n",
       "      <td>female</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>230433</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>882</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Markun, Mr. Johann</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>349257</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>883</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dahlberg, Miss. Gerda Ulrika</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7552</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>884</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Banfield, Mr. Frederick James</td>\n",
       "      <td>male</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C.A./SOTON 34068</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>885</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Sutehall, Mr. Henry Jr</td>\n",
       "      <td>male</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>SOTON/OQ 392076</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>886</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Rice, Mrs. William (Margaret Norton)</td>\n",
       "      <td>female</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>382652</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>887</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>Montvila, Rev. Juozas</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>211536</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>888</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Graham, Miss. Margaret Edith</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>112053</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>B42</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>889</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Johnston, Miss. Catherine Helen \"Carrie\"</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>W./C. 6607</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>890</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Behr, Mr. Karl Howell</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>111369</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C148</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>891</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Dooley, Mr. Patrick</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>370376</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "0              1         0       3   \n",
       "1              2         1       1   \n",
       "2              3         1       3   \n",
       "3              4         1       1   \n",
       "4              5         0       3   \n",
       "5              6         0       3   \n",
       "6              7         0       1   \n",
       "7              8         0       3   \n",
       "8              9         1       3   \n",
       "9             10         1       2   \n",
       "10            11         1       3   \n",
       "11            12         1       1   \n",
       "12            13         0       3   \n",
       "13            14         0       3   \n",
       "14            15         0       3   \n",
       "15            16         1       2   \n",
       "16            17         0       3   \n",
       "17            18         1       2   \n",
       "18            19         0       3   \n",
       "19            20         1       3   \n",
       "20            21         0       2   \n",
       "21            22         1       2   \n",
       "22            23         1       3   \n",
       "23            24         1       1   \n",
       "24            25         0       3   \n",
       "25            26         1       3   \n",
       "26            27         0       3   \n",
       "27            28         0       1   \n",
       "28            29         1       3   \n",
       "29            30         0       3   \n",
       "..           ...       ...     ...   \n",
       "861          862         0       2   \n",
       "862          863         1       1   \n",
       "863          864         0       3   \n",
       "864          865         0       2   \n",
       "865          866         1       2   \n",
       "866          867         1       2   \n",
       "867          868         0       1   \n",
       "868          869         0       3   \n",
       "869          870         1       3   \n",
       "870          871         0       3   \n",
       "871          872         1       1   \n",
       "872          873         0       1   \n",
       "873          874         0       3   \n",
       "874          875         1       2   \n",
       "875          876         1       3   \n",
       "876          877         0       3   \n",
       "877          878         0       3   \n",
       "878          879         0       3   \n",
       "879          880         1       1   \n",
       "880          881         1       2   \n",
       "881          882         0       3   \n",
       "882          883         0       3   \n",
       "883          884         0       2   \n",
       "884          885         0       3   \n",
       "885          886         0       3   \n",
       "886          887         0       2   \n",
       "887          888         1       1   \n",
       "888          889         0       3   \n",
       "889          890         1       1   \n",
       "890          891         0       3   \n",
       "\n",
       "                                                  Name     Sex   Age  SibSp  \\\n",
       "0                              Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1    Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                               Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3         Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                             Allen, Mr. William Henry    male  35.0      0   \n",
       "5                                     Moran, Mr. James    male   NaN      0   \n",
       "6                              McCarthy, Mr. Timothy J    male  54.0      0   \n",
       "7                       Palsson, Master. Gosta Leonard    male   2.0      3   \n",
       "8    Johnson, Mrs. Oscar W (Elisabeth Vilhelmina Berg)  female  27.0      0   \n",
       "9                  Nasser, Mrs. Nicholas (Adele Achem)  female  14.0      1   \n",
       "10                     Sandstrom, Miss. Marguerite Rut  female   4.0      1   \n",
       "11                            Bonnell, Miss. Elizabeth  female  58.0      0   \n",
       "12                      Saundercock, Mr. William Henry    male  20.0      0   \n",
       "13                         Andersson, Mr. Anders Johan    male  39.0      1   \n",
       "14                Vestrom, Miss. Hulda Amanda Adolfina  female  14.0      0   \n",
       "15                    Hewlett, Mrs. (Mary D Kingcome)   female  55.0      0   \n",
       "16                                Rice, Master. Eugene    male   2.0      4   \n",
       "17                        Williams, Mr. Charles Eugene    male   NaN      0   \n",
       "18   Vander Planke, Mrs. Julius (Emelia Maria Vande...  female  31.0      1   \n",
       "19                             Masselmani, Mrs. Fatima  female   NaN      0   \n",
       "20                                Fynney, Mr. Joseph J    male  35.0      0   \n",
       "21                               Beesley, Mr. Lawrence    male  34.0      0   \n",
       "22                         McGowan, Miss. Anna \"Annie\"  female  15.0      0   \n",
       "23                        Sloper, Mr. William Thompson    male  28.0      0   \n",
       "24                       Palsson, Miss. Torborg Danira  female   8.0      3   \n",
       "25   Asplund, Mrs. Carl Oscar (Selma Augusta Emilia...  female  38.0      1   \n",
       "26                             Emir, Mr. Farred Chehab    male   NaN      0   \n",
       "27                      Fortune, Mr. Charles Alexander    male  19.0      3   \n",
       "28                       O'Dwyer, Miss. Ellen \"Nellie\"  female   NaN      0   \n",
       "29                                 Todoroff, Mr. Lalio    male   NaN      0   \n",
       "..                                                 ...     ...   ...    ...   \n",
       "861                        Giles, Mr. Frederick Edward    male  21.0      1   \n",
       "862  Swift, Mrs. Frederick Joel (Margaret Welles Ba...  female  48.0      0   \n",
       "863                  Sage, Miss. Dorothy Edith \"Dolly\"  female   NaN      8   \n",
       "864                             Gill, Mr. John William    male  24.0      0   \n",
       "865                           Bystrom, Mrs. (Karolina)  female  42.0      0   \n",
       "866                       Duran y More, Miss. Asuncion  female  27.0      1   \n",
       "867               Roebling, Mr. Washington Augustus II    male  31.0      0   \n",
       "868                        van Melkebeke, Mr. Philemon    male   NaN      0   \n",
       "869                    Johnson, Master. Harold Theodor    male   4.0      1   \n",
       "870                                  Balkic, Mr. Cerin    male  26.0      0   \n",
       "871   Beckwith, Mrs. Richard Leonard (Sallie Monypeny)  female  47.0      1   \n",
       "872                           Carlsson, Mr. Frans Olof    male  33.0      0   \n",
       "873                        Vander Cruyssen, Mr. Victor    male  47.0      0   \n",
       "874              Abelson, Mrs. Samuel (Hannah Wizosky)  female  28.0      1   \n",
       "875                   Najib, Miss. Adele Kiamie \"Jane\"  female  15.0      0   \n",
       "876                      Gustafsson, Mr. Alfred Ossian    male  20.0      0   \n",
       "877                               Petroff, Mr. Nedelio    male  19.0      0   \n",
       "878                                 Laleff, Mr. Kristo    male   NaN      0   \n",
       "879      Potter, Mrs. Thomas Jr (Lily Alexenia Wilson)  female  56.0      0   \n",
       "880       Shelley, Mrs. William (Imanita Parrish Hall)  female  25.0      0   \n",
       "881                                 Markun, Mr. Johann    male  33.0      0   \n",
       "882                       Dahlberg, Miss. Gerda Ulrika  female  22.0      0   \n",
       "883                      Banfield, Mr. Frederick James    male  28.0      0   \n",
       "884                             Sutehall, Mr. Henry Jr    male  25.0      0   \n",
       "885               Rice, Mrs. William (Margaret Norton)  female  39.0      0   \n",
       "886                              Montvila, Rev. Juozas    male  27.0      0   \n",
       "887                       Graham, Miss. Margaret Edith  female  19.0      0   \n",
       "888           Johnston, Miss. Catherine Helen \"Carrie\"  female   NaN      1   \n",
       "889                              Behr, Mr. Karl Howell    male  26.0      0   \n",
       "890                                Dooley, Mr. Patrick    male  32.0      0   \n",
       "\n",
       "     Parch            Ticket      Fare        Cabin Embarked  \n",
       "0        0         A/5 21171    7.2500          NaN        S  \n",
       "1        0          PC 17599   71.2833          C85        C  \n",
       "2        0  STON/O2. 3101282    7.9250          NaN        S  \n",
       "3        0            113803   53.1000         C123        S  \n",
       "4        0            373450    8.0500          NaN        S  \n",
       "5        0            330877    8.4583          NaN        Q  \n",
       "6        0             17463   51.8625          E46        S  \n",
       "7        1            349909   21.0750          NaN        S  \n",
       "8        2            347742   11.1333          NaN        S  \n",
       "9        0            237736   30.0708          NaN        C  \n",
       "10       1           PP 9549   16.7000           G6        S  \n",
       "11       0            113783   26.5500         C103        S  \n",
       "12       0         A/5. 2151    8.0500          NaN        S  \n",
       "13       5            347082   31.2750          NaN        S  \n",
       "14       0            350406    7.8542          NaN        S  \n",
       "15       0            248706   16.0000          NaN        S  \n",
       "16       1            382652   29.1250          NaN        Q  \n",
       "17       0            244373   13.0000          NaN        S  \n",
       "18       0            345763   18.0000          NaN        S  \n",
       "19       0              2649    7.2250          NaN        C  \n",
       "20       0            239865   26.0000          NaN        S  \n",
       "21       0            248698   13.0000          D56        S  \n",
       "22       0            330923    8.0292          NaN        Q  \n",
       "23       0            113788   35.5000           A6        S  \n",
       "24       1            349909   21.0750          NaN        S  \n",
       "25       5            347077   31.3875          NaN        S  \n",
       "26       0              2631    7.2250          NaN        C  \n",
       "27       2             19950  263.0000  C23 C25 C27        S  \n",
       "28       0            330959    7.8792          NaN        Q  \n",
       "29       0            349216    7.8958          NaN        S  \n",
       "..     ...               ...       ...          ...      ...  \n",
       "861      0             28134   11.5000          NaN        S  \n",
       "862      0             17466   25.9292          D17        S  \n",
       "863      2          CA. 2343   69.5500          NaN        S  \n",
       "864      0            233866   13.0000          NaN        S  \n",
       "865      0            236852   13.0000          NaN        S  \n",
       "866      0     SC/PARIS 2149   13.8583          NaN        C  \n",
       "867      0          PC 17590   50.4958          A24        S  \n",
       "868      0            345777    9.5000          NaN        S  \n",
       "869      1            347742   11.1333          NaN        S  \n",
       "870      0            349248    7.8958          NaN        S  \n",
       "871      1             11751   52.5542          D35        S  \n",
       "872      0               695    5.0000  B51 B53 B55        S  \n",
       "873      0            345765    9.0000          NaN        S  \n",
       "874      0         P/PP 3381   24.0000          NaN        C  \n",
       "875      0              2667    7.2250          NaN        C  \n",
       "876      0              7534    9.8458          NaN        S  \n",
       "877      0            349212    7.8958          NaN        S  \n",
       "878      0            349217    7.8958          NaN        S  \n",
       "879      1             11767   83.1583          C50        C  \n",
       "880      1            230433   26.0000          NaN        S  \n",
       "881      0            349257    7.8958          NaN        S  \n",
       "882      0              7552   10.5167          NaN        S  \n",
       "883      0  C.A./SOTON 34068   10.5000          NaN        S  \n",
       "884      0   SOTON/OQ 392076    7.0500          NaN        S  \n",
       "885      5            382652   29.1250          NaN        Q  \n",
       "886      0            211536   13.0000          NaN        S  \n",
       "887      0            112053   30.0000          B42        S  \n",
       "888      2        W./C. 6607   23.4500          NaN        S  \n",
       "889      0            111369   30.0000         C148        C  \n",
       "890      0            370376    7.7500          NaN        Q  \n",
       "\n",
       "[891 rows x 12 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic = titanic.drop(\"Name\",axis = 1)\n",
    "titanic = titanic.drop(\"Ticket\",axis = 1)\n",
    "titanic = titanic.drop(\"Cabin\",axis = 1)\n",
    "titanic = titanic.drop(\"PassengerId\",axis = 1)\n",
    "titanic_test = titanic_test.drop(\"Name\",axis = 1)\n",
    "titanic_test = titanic_test.drop(\"Ticket\",axis = 1)\n",
    "titanic_test = titanic_test.drop(\"Cabin\",axis = 1)\n",
    "titanic_test = titanic_test.drop(\"PassengerId\",axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex   Age  SibSp  Parch      Fare Embarked\n",
       "0           0       3    0  22.0      1      0    7.2500        S\n",
       "1           1       1    1  38.0      1      0   71.2833        C\n",
       "2           1       3    1  26.0      0      0    7.9250        S\n",
       "3           1       1    1  35.0      1      0   53.1000        S\n",
       "4           0       3    0  35.0      0      0    8.0500        S\n",
       "5           0       3    0   NaN      0      0    8.4583        Q\n",
       "6           0       1    0  54.0      0      0   51.8625        S\n",
       "7           0       3    0   2.0      3      1   21.0750        S\n",
       "8           1       3    1  27.0      0      2   11.1333        S\n",
       "9           1       2    1  14.0      1      0   30.0708        C\n",
       "10          1       3    1   4.0      1      1   16.7000        S\n",
       "11          1       1    1  58.0      0      0   26.5500        S\n",
       "12          0       3    0  20.0      0      0    8.0500        S\n",
       "13          0       3    0  39.0      1      5   31.2750        S\n",
       "14          0       3    1  14.0      0      0    7.8542        S\n",
       "15          1       2    1  55.0      0      0   16.0000        S\n",
       "16          0       3    0   2.0      4      1   29.1250        Q\n",
       "17          1       2    0   NaN      0      0   13.0000        S\n",
       "18          0       3    1  31.0      1      0   18.0000        S\n",
       "19          1       3    1   NaN      0      0    7.2250        C\n",
       "20          0       2    0  35.0      0      0   26.0000        S\n",
       "21          1       2    0  34.0      0      0   13.0000        S\n",
       "22          1       3    1  15.0      0      0    8.0292        Q\n",
       "23          1       1    0  28.0      0      0   35.5000        S\n",
       "24          0       3    1   8.0      3      1   21.0750        S\n",
       "25          1       3    1  38.0      1      5   31.3875        S\n",
       "26          0       3    0   NaN      0      0    7.2250        C\n",
       "27          0       1    0  19.0      3      2  263.0000        S\n",
       "28          1       3    1   NaN      0      0    7.8792        Q\n",
       "29          0       3    0   NaN      0      0    7.8958        S\n",
       "..        ...     ...  ...   ...    ...    ...       ...      ...\n",
       "861         0       2    0  21.0      1      0   11.5000        S\n",
       "862         1       1    1  48.0      0      0   25.9292        S\n",
       "863         0       3    1   NaN      8      2   69.5500        S\n",
       "864         0       2    0  24.0      0      0   13.0000        S\n",
       "865         1       2    1  42.0      0      0   13.0000        S\n",
       "866         1       2    1  27.0      1      0   13.8583        C\n",
       "867         0       1    0  31.0      0      0   50.4958        S\n",
       "868         0       3    0   NaN      0      0    9.5000        S\n",
       "869         1       3    0   4.0      1      1   11.1333        S\n",
       "870         0       3    0  26.0      0      0    7.8958        S\n",
       "871         1       1    1  47.0      1      1   52.5542        S\n",
       "872         0       1    0  33.0      0      0    5.0000        S\n",
       "873         0       3    0  47.0      0      0    9.0000        S\n",
       "874         1       2    1  28.0      1      0   24.0000        C\n",
       "875         1       3    1  15.0      0      0    7.2250        C\n",
       "876         0       3    0  20.0      0      0    9.8458        S\n",
       "877         0       3    0  19.0      0      0    7.8958        S\n",
       "878         0       3    0   NaN      0      0    7.8958        S\n",
       "879         1       1    1  56.0      0      1   83.1583        C\n",
       "880         1       2    1  25.0      0      1   26.0000        S\n",
       "881         0       3    0  33.0      0      0    7.8958        S\n",
       "882         0       3    1  22.0      0      0   10.5167        S\n",
       "883         0       2    0  28.0      0      0   10.5000        S\n",
       "884         0       3    0  25.0      0      0    7.0500        S\n",
       "885         0       3    1  39.0      0      5   29.1250        Q\n",
       "886         0       2    0  27.0      0      0   13.0000        S\n",
       "887         1       1    1  19.0      0      0   30.0000        S\n",
       "888         0       3    1   NaN      1      2   23.4500        S\n",
       "889         1       1    0  26.0      0      0   30.0000        C\n",
       "890         0       3    0  32.0      0      0    7.7500        Q\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes, uniques = pd.factorize(pd.concat([titanic['Sex'], titanic_test['Sex']]))\n",
    "titanic['Sex'] = codes[:len(titanic)]\n",
    "titanic_test['Sex'] = codes[len(titanic):]\n",
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex   Age  SibSp  Parch      Fare  Embarked\n",
       "0           0       3    0  22.0      1      0    7.2500         0\n",
       "1           1       1    1  38.0      1      0   71.2833         1\n",
       "2           1       3    1  26.0      0      0    7.9250         0\n",
       "3           1       1    1  35.0      1      0   53.1000         0\n",
       "4           0       3    0  35.0      0      0    8.0500         0\n",
       "5           0       3    0   NaN      0      0    8.4583         2\n",
       "6           0       1    0  54.0      0      0   51.8625         0\n",
       "7           0       3    0   2.0      3      1   21.0750         0\n",
       "8           1       3    1  27.0      0      2   11.1333         0\n",
       "9           1       2    1  14.0      1      0   30.0708         1\n",
       "10          1       3    1   4.0      1      1   16.7000         0\n",
       "11          1       1    1  58.0      0      0   26.5500         0\n",
       "12          0       3    0  20.0      0      0    8.0500         0\n",
       "13          0       3    0  39.0      1      5   31.2750         0\n",
       "14          0       3    1  14.0      0      0    7.8542         0\n",
       "15          1       2    1  55.0      0      0   16.0000         0\n",
       "16          0       3    0   2.0      4      1   29.1250         2\n",
       "17          1       2    0   NaN      0      0   13.0000         0\n",
       "18          0       3    1  31.0      1      0   18.0000         0\n",
       "19          1       3    1   NaN      0      0    7.2250         1\n",
       "20          0       2    0  35.0      0      0   26.0000         0\n",
       "21          1       2    0  34.0      0      0   13.0000         0\n",
       "22          1       3    1  15.0      0      0    8.0292         2\n",
       "23          1       1    0  28.0      0      0   35.5000         0\n",
       "24          0       3    1   8.0      3      1   21.0750         0\n",
       "25          1       3    1  38.0      1      5   31.3875         0\n",
       "26          0       3    0   NaN      0      0    7.2250         1\n",
       "27          0       1    0  19.0      3      2  263.0000         0\n",
       "28          1       3    1   NaN      0      0    7.8792         2\n",
       "29          0       3    0   NaN      0      0    7.8958         0\n",
       "..        ...     ...  ...   ...    ...    ...       ...       ...\n",
       "861         0       2    0  21.0      1      0   11.5000         0\n",
       "862         1       1    1  48.0      0      0   25.9292         0\n",
       "863         0       3    1   NaN      8      2   69.5500         0\n",
       "864         0       2    0  24.0      0      0   13.0000         0\n",
       "865         1       2    1  42.0      0      0   13.0000         0\n",
       "866         1       2    1  27.0      1      0   13.8583         1\n",
       "867         0       1    0  31.0      0      0   50.4958         0\n",
       "868         0       3    0   NaN      0      0    9.5000         0\n",
       "869         1       3    0   4.0      1      1   11.1333         0\n",
       "870         0       3    0  26.0      0      0    7.8958         0\n",
       "871         1       1    1  47.0      1      1   52.5542         0\n",
       "872         0       1    0  33.0      0      0    5.0000         0\n",
       "873         0       3    0  47.0      0      0    9.0000         0\n",
       "874         1       2    1  28.0      1      0   24.0000         1\n",
       "875         1       3    1  15.0      0      0    7.2250         1\n",
       "876         0       3    0  20.0      0      0    9.8458         0\n",
       "877         0       3    0  19.0      0      0    7.8958         0\n",
       "878         0       3    0   NaN      0      0    7.8958         0\n",
       "879         1       1    1  56.0      0      1   83.1583         1\n",
       "880         1       2    1  25.0      0      1   26.0000         0\n",
       "881         0       3    0  33.0      0      0    7.8958         0\n",
       "882         0       3    1  22.0      0      0   10.5167         0\n",
       "883         0       2    0  28.0      0      0   10.5000         0\n",
       "884         0       3    0  25.0      0      0    7.0500         0\n",
       "885         0       3    1  39.0      0      5   29.1250         2\n",
       "886         0       2    0  27.0      0      0   13.0000         0\n",
       "887         1       1    1  19.0      0      0   30.0000         0\n",
       "888         0       3    1   NaN      1      2   23.4500         0\n",
       "889         1       1    0  26.0      0      0   30.0000         1\n",
       "890         0       3    0  32.0      0      0    7.7500         2\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "codes, uniques = pd.factorize(pd.concat([titanic['Embarked'], titanic_test['Embarked']]))\n",
    "titanic['Embarked'] = codes[:len(titanic)]\n",
    "titanic_test['Embarked'] = codes[len(titanic):]\n",
    "titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.4583</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>51.8625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0708</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>16.7000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>55.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>16.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0292</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.0750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>31.3875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>263.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8792</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>861</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>11.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>862</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>48.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25.9292</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>69.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>866</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>13.8583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>867</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.4958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>868</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>869</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>11.1333</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>870</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>876</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.8458</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>877</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>878</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>879</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>83.1583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>881</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5167</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>884</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>885</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>29.1250</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>27.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex        Age  SibSp  Parch      Fare  Embarked\n",
       "0           0       3    0  22.000000      1      0    7.2500         0\n",
       "1           1       1    1  38.000000      1      0   71.2833         1\n",
       "2           1       3    1  26.000000      0      0    7.9250         0\n",
       "3           1       1    1  35.000000      1      0   53.1000         0\n",
       "4           0       3    0  35.000000      0      0    8.0500         0\n",
       "5           0       3    0  29.699118      0      0    8.4583         2\n",
       "6           0       1    0  54.000000      0      0   51.8625         0\n",
       "7           0       3    0   2.000000      3      1   21.0750         0\n",
       "8           1       3    1  27.000000      0      2   11.1333         0\n",
       "9           1       2    1  14.000000      1      0   30.0708         1\n",
       "10          1       3    1   4.000000      1      1   16.7000         0\n",
       "11          1       1    1  58.000000      0      0   26.5500         0\n",
       "12          0       3    0  20.000000      0      0    8.0500         0\n",
       "13          0       3    0  39.000000      1      5   31.2750         0\n",
       "14          0       3    1  14.000000      0      0    7.8542         0\n",
       "15          1       2    1  55.000000      0      0   16.0000         0\n",
       "16          0       3    0   2.000000      4      1   29.1250         2\n",
       "17          1       2    0  29.699118      0      0   13.0000         0\n",
       "18          0       3    1  31.000000      1      0   18.0000         0\n",
       "19          1       3    1  29.699118      0      0    7.2250         1\n",
       "20          0       2    0  35.000000      0      0   26.0000         0\n",
       "21          1       2    0  34.000000      0      0   13.0000         0\n",
       "22          1       3    1  15.000000      0      0    8.0292         2\n",
       "23          1       1    0  28.000000      0      0   35.5000         0\n",
       "24          0       3    1   8.000000      3      1   21.0750         0\n",
       "25          1       3    1  38.000000      1      5   31.3875         0\n",
       "26          0       3    0  29.699118      0      0    7.2250         1\n",
       "27          0       1    0  19.000000      3      2  263.0000         0\n",
       "28          1       3    1  29.699118      0      0    7.8792         2\n",
       "29          0       3    0  29.699118      0      0    7.8958         0\n",
       "..        ...     ...  ...        ...    ...    ...       ...       ...\n",
       "861         0       2    0  21.000000      1      0   11.5000         0\n",
       "862         1       1    1  48.000000      0      0   25.9292         0\n",
       "863         0       3    1  29.699118      8      2   69.5500         0\n",
       "864         0       2    0  24.000000      0      0   13.0000         0\n",
       "865         1       2    1  42.000000      0      0   13.0000         0\n",
       "866         1       2    1  27.000000      1      0   13.8583         1\n",
       "867         0       1    0  31.000000      0      0   50.4958         0\n",
       "868         0       3    0  29.699118      0      0    9.5000         0\n",
       "869         1       3    0   4.000000      1      1   11.1333         0\n",
       "870         0       3    0  26.000000      0      0    7.8958         0\n",
       "871         1       1    1  47.000000      1      1   52.5542         0\n",
       "872         0       1    0  33.000000      0      0    5.0000         0\n",
       "873         0       3    0  47.000000      0      0    9.0000         0\n",
       "874         1       2    1  28.000000      1      0   24.0000         1\n",
       "875         1       3    1  15.000000      0      0    7.2250         1\n",
       "876         0       3    0  20.000000      0      0    9.8458         0\n",
       "877         0       3    0  19.000000      0      0    7.8958         0\n",
       "878         0       3    0  29.699118      0      0    7.8958         0\n",
       "879         1       1    1  56.000000      0      1   83.1583         1\n",
       "880         1       2    1  25.000000      0      1   26.0000         0\n",
       "881         0       3    0  33.000000      0      0    7.8958         0\n",
       "882         0       3    1  22.000000      0      0   10.5167         0\n",
       "883         0       2    0  28.000000      0      0   10.5000         0\n",
       "884         0       3    0  25.000000      0      0    7.0500         0\n",
       "885         0       3    1  39.000000      0      5   29.1250         2\n",
       "886         0       2    0  27.000000      0      0   13.0000         0\n",
       "887         1       1    1  19.000000      0      0   30.0000         0\n",
       "888         0       3    1  29.699118      1      2   23.4500         0\n",
       "889         1       1    0  26.000000      0      0   30.0000         1\n",
       "890         0       3    0  32.000000      0      0    7.7500         2\n",
       "\n",
       "[891 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.mean()\n",
    "titanic[\"Age\"].fillna(titanic.mean()[\"Age\"],inplace = True)\n",
    "titanic_test[\"Age\"].fillna(titanic.mean()[\"Age\"],inplace = True)\n",
    "titanic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X,Y =titanic.drop(\"Survived\",axis=1) ,titanic['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(891,)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "712 179\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(titanic, test_size = 0.2 , random_state = 42)\n",
    "print(len(train_set), len(test_set))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train,y_train = train_set.drop(\"Survived\",axis = 1),train_set['Survived']\n",
    "X_test, y_test =  test_set.drop(\"Survived\",axis = 1),test_set['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>331</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45.500000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>28.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>733</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>704</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>813</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>247.5208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>536</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.5500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>27.7208</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>35.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>865</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>595</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>24.1500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.2750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>721</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>486</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>90.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>716</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>800</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>781</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>57.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>31.2750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.2375</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>534</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>535</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>26.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>63.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.5875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>762</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2292</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>533</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>22.3583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>713</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.4833</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>390</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>14.4583</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>45.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>73.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>805</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7750</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>413</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>491</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>343</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>25.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>769</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.3625</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>24.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>33.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.8958</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.4958</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>47.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5542</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.5000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>330</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>23.2500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>614</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>35.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>700</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>227.5250</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>46.9000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.6500</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>270</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>31.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>14.1083</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>120.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>77.2875</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>712 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass  Sex        Age  SibSp  Parch      Fare  Embarked\n",
       "331       1    0  45.500000      0      0   28.5000         0\n",
       "733       2    0  23.000000      0      0   13.0000         0\n",
       "382       3    0  32.000000      0      0    7.9250         0\n",
       "704       3    0  26.000000      1      0    7.8542         0\n",
       "813       3    1   6.000000      4      2   31.2750         0\n",
       "118       1    0  24.000000      0      1  247.5208         1\n",
       "536       1    0  45.000000      0      0   26.5500         0\n",
       "361       2    0  29.000000      1      0   27.7208         1\n",
       "29        3    0  29.699118      0      0    7.8958         0\n",
       "55        1    0  29.699118      0      0   35.5000         0\n",
       "865       2    1  42.000000      0      0   13.0000         0\n",
       "595       3    0  36.000000      1      1   24.1500         0\n",
       "239       2    0  33.000000      0      0   12.2750         0\n",
       "721       3    0  17.000000      1      0    7.0542         0\n",
       "81        3    0  29.000000      0      0    9.5000         0\n",
       "259       2    1  50.000000      0      1   26.0000         0\n",
       "486       1    1  35.000000      1      0   90.0000         0\n",
       "716       1    1  38.000000      0      0  227.5250         1\n",
       "800       2    0  34.000000      0      0   13.0000         0\n",
       "781       1    1  17.000000      1      0   57.0000         0\n",
       "542       3    1  11.000000      4      2   31.2750         0\n",
       "326       3    0  61.000000      0      0    6.2375         0\n",
       "534       3    1  30.000000      0      0    8.6625         0\n",
       "535       2    1   7.000000      0      2   26.2500         0\n",
       "483       3    1  63.000000      0      0    9.5875         0\n",
       "762       3    0  20.000000      0      0    7.2292         1\n",
       "533       3    1  29.699118      0      2   22.3583         1\n",
       "713       3    0  29.000000      0      0    9.4833         0\n",
       "390       1    0  36.000000      1      2  120.0000         0\n",
       "495       3    0  29.699118      0      0   14.4583         1\n",
       "..      ...  ...        ...    ...    ...       ...       ...\n",
       "276       3    1  45.000000      0      0    7.7500         0\n",
       "191       2    0  19.000000      0      0   13.0000         0\n",
       "385       2    0  18.000000      0      0   73.5000         0\n",
       "805       3    0  31.000000      0      0    7.7750         0\n",
       "413       2    0  29.699118      0      0    0.0000         0\n",
       "491       3    0  21.000000      0      0    7.2500         0\n",
       "343       2    0  25.000000      0      0   13.0000         0\n",
       "769       3    0  32.000000      0      0    8.3625         0\n",
       "308       2    0  30.000000      1      0   24.0000         1\n",
       "661       3    0  40.000000      0      0    7.2250         1\n",
       "130       3    0  33.000000      0      0    7.8958         1\n",
       "663       3    0  36.000000      0      0    7.4958         0\n",
       "871       1    1  47.000000      1      1   52.5542         0\n",
       "99        2    0  34.000000      1      0   26.0000         0\n",
       "372       3    0  19.000000      0      0    8.0500         0\n",
       "87        3    0  29.699118      0      0    8.0500         0\n",
       "458       2    1  50.000000      0      0   10.5000         0\n",
       "330       3    1  29.699118      2      0   23.2500         2\n",
       "214       3    0  29.699118      1      0    7.7500         2\n",
       "466       2    0  29.699118      0      0    0.0000         0\n",
       "121       3    0  29.699118      0      0    8.0500         0\n",
       "614       3    0  35.000000      0      0    8.0500         0\n",
       "20        2    0  35.000000      0      0   26.0000         0\n",
       "700       1    1  18.000000      1      0  227.5250         1\n",
       "71        3    1  16.000000      5      2   46.9000         0\n",
       "106       3    1  21.000000      0      0    7.6500         0\n",
       "270       1    0  29.699118      0      0   31.0000         0\n",
       "860       3    0  41.000000      2      0   14.1083         0\n",
       "435       1    1  14.000000      1      2  120.0000         0\n",
       "102       1    0  21.000000      0      1   77.2875         0\n",
       "\n",
       "[712 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
       "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
       "       learning_rate='optimal', loss='hinge', n_iter=5, n_jobs=1,\n",
       "       penalty='l2', power_t=0.5, random_state=42, shuffle=True, verbose=0,\n",
       "       warm_start=False)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "sgd_clf = SGDClassifier(random_state=42)\n",
    "sgd_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.62605042,  0.67510549,  0.62447257])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.79831933,  0.78481013,  0.8185654 ])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "forest_clf = RandomForestClassifier(random_state=42)\n",
    "cross_val_score(forest_clf, X_train, y_train, cv=3,\n",
    "                                    scoring = \"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "forest_clf.fit(X_train,y_train)\n",
    "predictions = forest_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.78770949720670391"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.70168067,  0.71729958,  0.74261603])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_clf = KNeighborsClassifier(n_jobs=-1, weights='distance', n_neighbors=8)\n",
    "cross_val_score(knn_clf, X_train, y_train, cv=3,\n",
    "                                    scoring = \"accuracy\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=-1, n_neighbors=8, p=2,\n",
       "           weights=u'distance'),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid=[{u'n_neighbors': [2, 4, 6, 8, 10]}],\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=u'neg_mean_squared_error', verbose=0)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "param_grid = [\n",
    "    # try 12 (3×4) combinations of hyperparameters\n",
    "    {'n_neighbors': [2, 4, 6, 8,10]},\n",
    "  ]\n",
    "grid_search = GridSearchCV(knn_clf, param_grid, cv=5,\n",
    "                           scoring='neg_mean_squared_error')\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{u'n_neighbors': 8}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "knn_clf.fit(X_train,y_train)\n",
    "predictions =knn_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73743016759776536"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97206703910614523"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_clf.fit(X,Y)\n",
    "pred_for =forest_clf.predict(X_test)\n",
    "accuracy_score(y_test,pred_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([152]), array([5]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.where(pd.isnull(titanic_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "titanic_test[\"Fare\"].fillna(titanic.mean()[\"Fare\"],inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "predict = forest_clf.predict(titanic_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": load_housing_data(path = \"test.csv\")[\"PassengerId\"],\n",
    "        \"Survived\": predict\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "csv_path = os.path.join(HOUSING_PATH, \"submission.csv\")\n",
    "submission.to_csv(csv_path, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: /tmp/tmphfUNpl\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_ps_replicas': 0, '_keep_checkpoint_max': 5, '_task_type': None, '_is_chief': True, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f0d70c40fd0>, '_model_dir': '/tmp/tmphfUNpl', '_save_checkpoints_steps': None, '_keep_checkpoint_every_n_hours': 10000, '_session_config': None, '_tf_random_seed': None, '_save_summary_steps': 100, '_environment': 'local', '_num_worker_replicas': 0, '_task_id': 0, '_log_step_count_steps': 100, '_tf_config': gpu_options {\n",
      "  per_process_gpu_memory_fraction: 1.0\n",
      "}\n",
      ", '_evaluation_master': '', '_master': ''}\n",
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/tmphfUNpl/model.ckpt.\n",
      "INFO:tensorflow:loss = 3.32333, step = 1\n",
      "INFO:tensorflow:global_step/sec: 245.402\n",
      "INFO:tensorflow:loss = 0.634354, step = 101 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.719\n",
      "INFO:tensorflow:loss = 0.704504, step = 201 (0.451 sec)\n",
      "INFO:tensorflow:global_step/sec: 223.131\n",
      "INFO:tensorflow:loss = 0.597474, step = 301 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.815\n",
      "INFO:tensorflow:loss = 0.668726, step = 401 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 168.568\n",
      "INFO:tensorflow:loss = 0.54818, step = 501 (0.594 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.317\n",
      "INFO:tensorflow:loss = 0.473746, step = 601 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.163\n",
      "INFO:tensorflow:loss = 0.436813, step = 701 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.106\n",
      "INFO:tensorflow:loss = 0.328876, step = 801 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.757\n",
      "INFO:tensorflow:loss = 0.404694, step = 901 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.07\n",
      "INFO:tensorflow:loss = 0.487114, step = 1001 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 163.833\n",
      "INFO:tensorflow:loss = 0.604101, step = 1101 (0.611 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.772\n",
      "INFO:tensorflow:loss = 0.481199, step = 1201 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.62\n",
      "INFO:tensorflow:loss = 0.355625, step = 1301 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.6\n",
      "INFO:tensorflow:loss = 0.423917, step = 1401 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.53\n",
      "INFO:tensorflow:loss = 0.523937, step = 1501 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.025\n",
      "INFO:tensorflow:loss = 0.398897, step = 1601 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.056\n",
      "INFO:tensorflow:loss = 0.421235, step = 1701 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.624\n",
      "INFO:tensorflow:loss = 0.442075, step = 1801 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.405\n",
      "INFO:tensorflow:loss = 0.387244, step = 1901 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.374\n",
      "INFO:tensorflow:loss = 0.349393, step = 2001 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.463\n",
      "INFO:tensorflow:loss = 0.363835, step = 2101 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 173.567\n",
      "INFO:tensorflow:loss = 0.403595, step = 2201 (0.580 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.777\n",
      "INFO:tensorflow:loss = 0.445276, step = 2301 (0.469 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.698\n",
      "INFO:tensorflow:loss = 0.539512, step = 2401 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.467\n",
      "INFO:tensorflow:loss = 0.361859, step = 2501 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.363\n",
      "INFO:tensorflow:loss = 0.473864, step = 2601 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.596\n",
      "INFO:tensorflow:loss = 0.346206, step = 2701 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.935\n",
      "INFO:tensorflow:loss = 0.302968, step = 2801 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.025\n",
      "INFO:tensorflow:loss = 0.307773, step = 2901 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.856\n",
      "INFO:tensorflow:loss = 0.369473, step = 3001 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.499\n",
      "INFO:tensorflow:loss = 0.307824, step = 3101 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.967\n",
      "INFO:tensorflow:loss = 0.51715, step = 3201 (0.509 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.582\n",
      "INFO:tensorflow:loss = 0.401998, step = 3301 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.391\n",
      "INFO:tensorflow:loss = 0.319113, step = 3401 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.493\n",
      "INFO:tensorflow:loss = 0.269947, step = 3501 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 217.285\n",
      "INFO:tensorflow:loss = 0.342364, step = 3601 (0.462 sec)\n",
      "INFO:tensorflow:global_step/sec: 222.974\n",
      "INFO:tensorflow:loss = 0.508322, step = 3701 (0.447 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.6\n",
      "INFO:tensorflow:loss = 0.313516, step = 3801 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.316\n",
      "INFO:tensorflow:loss = 0.373276, step = 3901 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.771\n",
      "INFO:tensorflow:loss = 0.360538, step = 4001 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.718\n",
      "INFO:tensorflow:loss = 0.216501, step = 4101 (0.514 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.126\n",
      "INFO:tensorflow:loss = 0.330785, step = 4201 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.727\n",
      "INFO:tensorflow:loss = 0.284261, step = 4301 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.141\n",
      "INFO:tensorflow:loss = 0.248432, step = 4401 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.886\n",
      "INFO:tensorflow:loss = 0.387323, step = 4501 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.86\n",
      "INFO:tensorflow:loss = 0.210595, step = 4601 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.367\n",
      "INFO:tensorflow:loss = 0.289193, step = 4701 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.885\n",
      "INFO:tensorflow:loss = 0.335699, step = 4801 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.917\n",
      "INFO:tensorflow:loss = 0.224999, step = 4901 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.939\n",
      "INFO:tensorflow:loss = 0.306705, step = 5001 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.783\n",
      "INFO:tensorflow:loss = 0.260985, step = 5101 (0.532 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.152\n",
      "INFO:tensorflow:loss = 0.351174, step = 5201 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.837\n",
      "INFO:tensorflow:loss = 0.409853, step = 5301 (0.520 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.857\n",
      "INFO:tensorflow:loss = 0.246759, step = 5401 (0.535 sec)\n",
      "INFO:tensorflow:global_step/sec: 135.468\n",
      "INFO:tensorflow:loss = 0.238898, step = 5501 (0.736 sec)\n",
      "INFO:tensorflow:global_step/sec: 140.523\n",
      "INFO:tensorflow:loss = 0.340333, step = 5601 (0.711 sec)\n",
      "INFO:tensorflow:global_step/sec: 149.576\n",
      "INFO:tensorflow:loss = 0.470122, step = 5701 (0.668 sec)\n",
      "INFO:tensorflow:global_step/sec: 147.789\n",
      "INFO:tensorflow:loss = 0.299309, step = 5801 (0.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 143.47\n",
      "INFO:tensorflow:loss = 0.230441, step = 5901 (0.699 sec)\n",
      "INFO:tensorflow:global_step/sec: 146.406\n",
      "INFO:tensorflow:loss = 0.277795, step = 6001 (0.683 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.806\n",
      "INFO:tensorflow:loss = 0.414516, step = 6101 (0.527 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.015\n",
      "INFO:tensorflow:loss = 0.284564, step = 6201 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.682\n",
      "INFO:tensorflow:loss = 0.395217, step = 6301 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.122\n",
      "INFO:tensorflow:loss = 0.260451, step = 6401 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.064\n",
      "INFO:tensorflow:loss = 0.260107, step = 6501 (0.565 sec)\n",
      "INFO:tensorflow:global_step/sec: 148.102\n",
      "INFO:tensorflow:loss = 0.265698, step = 6601 (0.678 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.404\n",
      "INFO:tensorflow:loss = 0.17181, step = 6701 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 170.609\n",
      "INFO:tensorflow:loss = 0.325169, step = 6801 (0.584 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.776\n",
      "INFO:tensorflow:loss = 0.256078, step = 6901 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.17\n",
      "INFO:tensorflow:loss = 0.292309, step = 7001 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 227.418\n",
      "INFO:tensorflow:loss = 0.291363, step = 7101 (0.440 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.158\n",
      "INFO:tensorflow:loss = 0.276703, step = 7201 (0.420 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.025\n",
      "INFO:tensorflow:loss = 0.234673, step = 7301 (0.412 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:global_step/sec: 246.328\n",
      "INFO:tensorflow:loss = 0.252832, step = 7401 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.682\n",
      "INFO:tensorflow:loss = 0.419448, step = 7501 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.683\n",
      "INFO:tensorflow:loss = 0.294777, step = 7601 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.556\n",
      "INFO:tensorflow:loss = 0.197757, step = 7701 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.62\n",
      "INFO:tensorflow:loss = 0.254186, step = 7801 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.293\n",
      "INFO:tensorflow:loss = 0.408204, step = 7901 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.077\n",
      "INFO:tensorflow:loss = 0.367325, step = 8001 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.313\n",
      "INFO:tensorflow:loss = 0.23909, step = 8101 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.182\n",
      "INFO:tensorflow:loss = 0.327814, step = 8201 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.717\n",
      "INFO:tensorflow:loss = 0.267023, step = 8301 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.747\n",
      "INFO:tensorflow:loss = 0.110499, step = 8401 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 232.466\n",
      "INFO:tensorflow:loss = 0.346433, step = 8501 (0.430 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.488\n",
      "INFO:tensorflow:loss = 0.193309, step = 8601 (0.471 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.215\n",
      "INFO:tensorflow:loss = 0.203324, step = 8701 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.626\n",
      "INFO:tensorflow:loss = 0.257169, step = 8801 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.53\n",
      "INFO:tensorflow:loss = 0.255413, step = 8901 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.583\n",
      "INFO:tensorflow:loss = 0.183696, step = 9001 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.479\n",
      "INFO:tensorflow:loss = 0.207762, step = 9101 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.161\n",
      "INFO:tensorflow:loss = 0.241754, step = 9201 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.774\n",
      "INFO:tensorflow:loss = 0.274702, step = 9301 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.882\n",
      "INFO:tensorflow:loss = 0.192108, step = 9401 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.486\n",
      "INFO:tensorflow:loss = 0.24275, step = 9501 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.342\n",
      "INFO:tensorflow:loss = 0.265666, step = 9601 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.248\n",
      "INFO:tensorflow:loss = 0.250552, step = 9701 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 256.679\n",
      "INFO:tensorflow:loss = 0.23593, step = 9801 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.371\n",
      "INFO:tensorflow:loss = 0.458206, step = 9901 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 255.988\n",
      "INFO:tensorflow:loss = 0.196553, step = 10001 (0.391 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.064\n",
      "INFO:tensorflow:loss = 0.173304, step = 10101 (0.429 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.443\n",
      "INFO:tensorflow:loss = 0.308658, step = 10201 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.086\n",
      "INFO:tensorflow:loss = 0.150103, step = 10301 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.983\n",
      "INFO:tensorflow:loss = 0.140068, step = 10401 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.113\n",
      "INFO:tensorflow:loss = 0.329232, step = 10501 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 259.694\n",
      "INFO:tensorflow:loss = 0.229747, step = 10601 (0.385 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.399\n",
      "INFO:tensorflow:loss = 0.273612, step = 10701 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.743\n",
      "INFO:tensorflow:loss = 0.325693, step = 10801 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.843\n",
      "INFO:tensorflow:loss = 0.136703, step = 10901 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.99\n",
      "INFO:tensorflow:loss = 0.105025, step = 11001 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.869\n",
      "INFO:tensorflow:loss = 0.127671, step = 11101 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.849\n",
      "INFO:tensorflow:loss = 0.328899, step = 11201 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.012\n",
      "INFO:tensorflow:loss = 0.181466, step = 11301 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.242\n",
      "INFO:tensorflow:loss = 0.39895, step = 11401 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.335\n",
      "INFO:tensorflow:loss = 0.261843, step = 11501 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.385\n",
      "INFO:tensorflow:loss = 0.276023, step = 11601 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.403\n",
      "INFO:tensorflow:loss = 0.248457, step = 11701 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.937\n",
      "INFO:tensorflow:loss = 0.235611, step = 11801 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.03\n",
      "INFO:tensorflow:loss = 0.297291, step = 11901 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.221\n",
      "INFO:tensorflow:loss = 0.272106, step = 12001 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.417\n",
      "INFO:tensorflow:loss = 0.259036, step = 12101 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.521\n",
      "INFO:tensorflow:loss = 0.0975181, step = 12201 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.55\n",
      "INFO:tensorflow:loss = 0.300566, step = 12301 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 257.383\n",
      "INFO:tensorflow:loss = 0.300784, step = 12401 (0.390 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.114\n",
      "INFO:tensorflow:loss = 0.11841, step = 12501 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.194\n",
      "INFO:tensorflow:loss = 0.184816, step = 12601 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.191\n",
      "INFO:tensorflow:loss = 0.103496, step = 12701 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.51\n",
      "INFO:tensorflow:loss = 0.254171, step = 12801 (0.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.69\n",
      "INFO:tensorflow:loss = 0.204944, step = 12901 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.778\n",
      "INFO:tensorflow:loss = 0.139056, step = 13001 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.889\n",
      "INFO:tensorflow:loss = 0.193992, step = 13101 (0.392 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.772\n",
      "INFO:tensorflow:loss = 0.162292, step = 13201 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 213.512\n",
      "INFO:tensorflow:loss = 0.123817, step = 13301 (0.468 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.273\n",
      "INFO:tensorflow:loss = 0.171275, step = 13401 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 258.16\n",
      "INFO:tensorflow:loss = 0.176913, step = 13501 (0.387 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.241\n",
      "INFO:tensorflow:loss = 0.203538, step = 13601 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.524\n",
      "INFO:tensorflow:loss = 0.194804, step = 13701 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.755\n",
      "INFO:tensorflow:loss = 0.255113, step = 13801 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.396\n",
      "INFO:tensorflow:loss = 0.234494, step = 13901 (0.548 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.362\n",
      "INFO:tensorflow:loss = 0.245267, step = 14001 (0.393 sec)\n",
      "INFO:tensorflow:global_step/sec: 252.997\n",
      "INFO:tensorflow:loss = 0.210209, step = 14101 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.728\n",
      "INFO:tensorflow:loss = 0.136273, step = 14201 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.308\n",
      "INFO:tensorflow:loss = 0.1201, step = 14301 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.029\n",
      "INFO:tensorflow:loss = 0.234185, step = 14401 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.074\n",
      "INFO:tensorflow:loss = 0.319647, step = 14501 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.659\n",
      "INFO:tensorflow:loss = 0.286349, step = 14601 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.802\n",
      "INFO:tensorflow:loss = 0.10646, step = 14701 (0.544 sec)\n",
      "INFO:tensorflow:global_step/sec: 183.899\n",
      "INFO:tensorflow:loss = 0.158832, step = 14801 (0.545 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.497\n",
      "INFO:tensorflow:loss = 0.208368, step = 14901 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.793\n",
      "INFO:tensorflow:loss = 0.134053, step = 15001 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.311\n",
      "INFO:tensorflow:loss = 0.201837, step = 15101 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.233\n",
      "INFO:tensorflow:loss = 0.348308, step = 15201 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.964\n",
      "INFO:tensorflow:loss = 0.178821, step = 15301 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.478\n",
      "INFO:tensorflow:loss = 0.243933, step = 15401 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.055\n",
      "INFO:tensorflow:loss = 0.189735, step = 15501 (0.394 sec)\n",
      "INFO:tensorflow:global_step/sec: 160.471\n",
      "INFO:tensorflow:loss = 0.111884, step = 15601 (0.626 sec)\n",
      "INFO:tensorflow:global_step/sec: 175.618\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.173682, step = 15701 (0.567 sec)\n",
      "INFO:tensorflow:global_step/sec: 182.884\n",
      "INFO:tensorflow:loss = 0.171692, step = 15801 (0.547 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.963\n",
      "INFO:tensorflow:loss = 0.260209, step = 15901 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.726\n",
      "INFO:tensorflow:loss = 0.166079, step = 16001 (0.519 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.03\n",
      "INFO:tensorflow:loss = 0.113388, step = 16101 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.985\n",
      "INFO:tensorflow:loss = 0.216497, step = 16201 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.076\n",
      "INFO:tensorflow:loss = 0.248984, step = 16301 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.955\n",
      "INFO:tensorflow:loss = 0.152577, step = 16401 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.988\n",
      "INFO:tensorflow:loss = 0.176617, step = 16501 (0.555 sec)\n",
      "INFO:tensorflow:global_step/sec: 164.207\n",
      "INFO:tensorflow:loss = 0.254844, step = 16601 (0.608 sec)\n",
      "INFO:tensorflow:global_step/sec: 167.232\n",
      "INFO:tensorflow:loss = 0.17258, step = 16701 (0.599 sec)\n",
      "INFO:tensorflow:global_step/sec: 174.33\n",
      "INFO:tensorflow:loss = 0.197395, step = 16801 (0.570 sec)\n",
      "INFO:tensorflow:global_step/sec: 192.228\n",
      "INFO:tensorflow:loss = 0.199506, step = 16901 (0.521 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.66\n",
      "INFO:tensorflow:loss = 0.215584, step = 17001 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.785\n",
      "INFO:tensorflow:loss = 0.0962551, step = 17101 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.522\n",
      "INFO:tensorflow:loss = 0.152956, step = 17201 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.184\n",
      "INFO:tensorflow:loss = 0.124229, step = 17301 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.462\n",
      "INFO:tensorflow:loss = 0.168754, step = 17401 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.454\n",
      "INFO:tensorflow:loss = 0.104778, step = 17501 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.503\n",
      "INFO:tensorflow:loss = 0.248, step = 17601 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.637\n",
      "INFO:tensorflow:loss = 0.122095, step = 17701 (0.475 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.48\n",
      "INFO:tensorflow:loss = 0.339391, step = 17801 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.824\n",
      "INFO:tensorflow:loss = 0.247529, step = 17901 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.696\n",
      "INFO:tensorflow:loss = 0.121923, step = 18001 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.521\n",
      "INFO:tensorflow:loss = 0.0944997, step = 18101 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.903\n",
      "INFO:tensorflow:loss = 0.175301, step = 18201 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.179\n",
      "INFO:tensorflow:loss = 0.161352, step = 18301 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.311\n",
      "INFO:tensorflow:loss = 0.158972, step = 18401 (0.427 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.026\n",
      "INFO:tensorflow:loss = 0.232597, step = 18501 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.213\n",
      "INFO:tensorflow:loss = 0.24035, step = 18601 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.973\n",
      "INFO:tensorflow:loss = 0.22955, step = 18701 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.317\n",
      "INFO:tensorflow:loss = 0.272037, step = 18801 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.632\n",
      "INFO:tensorflow:loss = 0.119945, step = 18901 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.682\n",
      "INFO:tensorflow:loss = 0.153137, step = 19001 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.01\n",
      "INFO:tensorflow:loss = 0.157021, step = 19101 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.692\n",
      "INFO:tensorflow:loss = 0.203849, step = 19201 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.829\n",
      "INFO:tensorflow:loss = 0.181752, step = 19301 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.941\n",
      "INFO:tensorflow:loss = 0.180279, step = 19401 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.387\n",
      "INFO:tensorflow:loss = 0.0655638, step = 19501 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.1\n",
      "INFO:tensorflow:loss = 0.129007, step = 19601 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.57\n",
      "INFO:tensorflow:loss = 0.169856, step = 19701 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.749\n",
      "INFO:tensorflow:loss = 0.195931, step = 19801 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.638\n",
      "INFO:tensorflow:loss = 0.198804, step = 19901 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.227\n",
      "INFO:tensorflow:loss = 0.0810709, step = 20001 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.932\n",
      "INFO:tensorflow:loss = 0.242817, step = 20101 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.51\n",
      "INFO:tensorflow:loss = 0.179615, step = 20201 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.601\n",
      "INFO:tensorflow:loss = 0.151273, step = 20301 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 215.282\n",
      "INFO:tensorflow:loss = 0.203051, step = 20401 (0.465 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.576\n",
      "INFO:tensorflow:loss = 0.0866231, step = 20501 (0.476 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.411\n",
      "INFO:tensorflow:loss = 0.22152, step = 20601 (0.453 sec)\n",
      "INFO:tensorflow:global_step/sec: 186.102\n",
      "INFO:tensorflow:loss = 0.22826, step = 20701 (0.538 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.727\n",
      "INFO:tensorflow:loss = 0.172377, step = 20801 (0.517 sec)\n",
      "INFO:tensorflow:global_step/sec: 188.421\n",
      "INFO:tensorflow:loss = 0.197104, step = 20901 (0.530 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.954\n",
      "INFO:tensorflow:loss = 0.190025, step = 21001 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.521\n",
      "INFO:tensorflow:loss = 0.0544316, step = 21101 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.964\n",
      "INFO:tensorflow:loss = 0.276535, step = 21201 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.74\n",
      "INFO:tensorflow:loss = 0.15825, step = 21301 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.38\n",
      "INFO:tensorflow:loss = 0.194656, step = 21401 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.904\n",
      "INFO:tensorflow:loss = 0.182614, step = 21501 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 191.649\n",
      "INFO:tensorflow:loss = 0.170834, step = 21601 (0.523 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.442\n",
      "INFO:tensorflow:loss = 0.120172, step = 21701 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.398\n",
      "INFO:tensorflow:loss = 0.0568121, step = 21801 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.503\n",
      "INFO:tensorflow:loss = 0.237524, step = 21901 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.459\n",
      "INFO:tensorflow:loss = 0.1783, step = 22001 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.167\n",
      "INFO:tensorflow:loss = 0.149208, step = 22101 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.384\n",
      "INFO:tensorflow:loss = 0.285286, step = 22201 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.237\n",
      "INFO:tensorflow:loss = 0.218162, step = 22301 (0.502 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.874\n",
      "INFO:tensorflow:loss = 0.180845, step = 22401 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.875\n",
      "INFO:tensorflow:loss = 0.266891, step = 22501 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.514\n",
      "INFO:tensorflow:loss = 0.149167, step = 22601 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 180.881\n",
      "INFO:tensorflow:loss = 0.13621, step = 22701 (0.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.748\n",
      "INFO:tensorflow:loss = 0.178441, step = 22801 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.832\n",
      "INFO:tensorflow:loss = 0.0977642, step = 22901 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.213\n",
      "INFO:tensorflow:loss = 0.0850955, step = 23001 (0.404 sec)\n",
      "INFO:tensorflow:global_step/sec: 250.026\n",
      "INFO:tensorflow:loss = 0.208308, step = 23101 (0.400 sec)\n",
      "INFO:tensorflow:global_step/sec: 181.16\n",
      "INFO:tensorflow:loss = 0.0752084, step = 23201 (0.553 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.824\n",
      "INFO:tensorflow:loss = 0.292766, step = 23301 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.191\n",
      "INFO:tensorflow:loss = 0.210203, step = 23401 (0.516 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.326\n",
      "INFO:tensorflow:loss = 0.149828, step = 23501 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.607\n",
      "INFO:tensorflow:loss = 0.191433, step = 23601 (0.414 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.476\n",
      "INFO:tensorflow:loss = 0.137464, step = 23701 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.328\n",
      "INFO:tensorflow:loss = 0.216657, step = 23801 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.841\n",
      "INFO:tensorflow:loss = 0.171059, step = 23901 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.164285, step = 24001 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.14\n",
      "INFO:tensorflow:loss = 0.133573, step = 24101 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.129\n",
      "INFO:tensorflow:loss = 0.072638, step = 24201 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.364\n",
      "INFO:tensorflow:loss = 0.0754976, step = 24301 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.922\n",
      "INFO:tensorflow:loss = 0.166121, step = 24401 (0.399 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.421\n",
      "INFO:tensorflow:loss = 0.182792, step = 24501 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.215\n",
      "INFO:tensorflow:loss = 0.0783741, step = 24601 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.497\n",
      "INFO:tensorflow:loss = 0.161554, step = 24701 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.105\n",
      "INFO:tensorflow:loss = 0.0818821, step = 24801 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.427\n",
      "INFO:tensorflow:loss = 0.162737, step = 24901 (0.435 sec)\n",
      "INFO:tensorflow:global_step/sec: 210.484\n",
      "INFO:tensorflow:loss = 0.124199, step = 25001 (0.474 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.087\n",
      "INFO:tensorflow:loss = 0.109556, step = 25101 (0.511 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.193\n",
      "INFO:tensorflow:loss = 0.129358, step = 25201 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.127\n",
      "INFO:tensorflow:loss = 0.17895, step = 25301 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.754\n",
      "INFO:tensorflow:loss = 0.0598922, step = 25401 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 212.58\n",
      "INFO:tensorflow:loss = 0.173424, step = 25501 (0.470 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.758\n",
      "INFO:tensorflow:loss = 0.111475, step = 25601 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.172\n",
      "INFO:tensorflow:loss = 0.12962, step = 25701 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.506\n",
      "INFO:tensorflow:loss = 0.183719, step = 25801 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.083\n",
      "INFO:tensorflow:loss = 0.146767, step = 25901 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.816\n",
      "INFO:tensorflow:loss = 0.0729491, step = 26001 (0.413 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.702\n",
      "INFO:tensorflow:loss = 0.162986, step = 26101 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.376\n",
      "INFO:tensorflow:loss = 0.172096, step = 26201 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 238.838\n",
      "INFO:tensorflow:loss = 0.16795, step = 26301 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.56\n",
      "INFO:tensorflow:loss = 0.172328, step = 26401 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 194.65\n",
      "INFO:tensorflow:loss = 0.140738, step = 26501 (0.513 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.478\n",
      "INFO:tensorflow:loss = 0.154893, step = 26601 (0.478 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.212\n",
      "INFO:tensorflow:loss = 0.163603, step = 26701 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.519\n",
      "INFO:tensorflow:loss = 0.120038, step = 26801 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.075\n",
      "INFO:tensorflow:loss = 0.218168, step = 26901 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 179.766\n",
      "INFO:tensorflow:loss = 0.204072, step = 27001 (0.554 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.07\n",
      "INFO:tensorflow:loss = 0.10951, step = 27101 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.398\n",
      "INFO:tensorflow:loss = 0.102856, step = 27201 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.858\n",
      "INFO:tensorflow:loss = 0.200024, step = 27301 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.618\n",
      "INFO:tensorflow:loss = 0.106384, step = 27401 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.34\n",
      "INFO:tensorflow:loss = 0.0347246, step = 27501 (0.499 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.193\n",
      "INFO:tensorflow:loss = 0.0759634, step = 27601 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.102\n",
      "INFO:tensorflow:loss = 0.0894485, step = 27701 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.942\n",
      "INFO:tensorflow:loss = 0.121615, step = 27801 (0.498 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.48\n",
      "INFO:tensorflow:loss = 0.188679, step = 27901 (0.497 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.57\n",
      "INFO:tensorflow:loss = 0.158698, step = 28001 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.269\n",
      "INFO:tensorflow:loss = 0.184401, step = 28101 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.519\n",
      "INFO:tensorflow:loss = 0.108814, step = 28201 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.24\n",
      "INFO:tensorflow:loss = 0.187218, step = 28301 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.622\n",
      "INFO:tensorflow:loss = 0.223486, step = 28401 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.604\n",
      "INFO:tensorflow:loss = 0.15163, step = 28501 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.354\n",
      "INFO:tensorflow:loss = 0.209023, step = 28601 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.453\n",
      "INFO:tensorflow:loss = 0.105759, step = 28701 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 178.666\n",
      "INFO:tensorflow:loss = 0.154282, step = 28801 (0.559 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.731\n",
      "INFO:tensorflow:loss = 0.118799, step = 28901 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.989\n",
      "INFO:tensorflow:loss = 0.172627, step = 29001 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.4\n",
      "INFO:tensorflow:loss = 0.225688, step = 29101 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.141\n",
      "INFO:tensorflow:loss = 0.20279, step = 29201 (0.504 sec)\n",
      "INFO:tensorflow:global_step/sec: 187.048\n",
      "INFO:tensorflow:loss = 0.0914996, step = 29301 (0.534 sec)\n",
      "INFO:tensorflow:global_step/sec: 234.831\n",
      "INFO:tensorflow:loss = 0.171248, step = 29401 (0.426 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.809\n",
      "INFO:tensorflow:loss = 0.212844, step = 29501 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.977\n",
      "INFO:tensorflow:loss = 0.163426, step = 29601 (0.421 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.457\n",
      "INFO:tensorflow:loss = 0.228495, step = 29701 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.229\n",
      "INFO:tensorflow:loss = 0.18403, step = 29801 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 226.492\n",
      "INFO:tensorflow:loss = 0.16796, step = 29901 (0.441 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.533\n",
      "INFO:tensorflow:loss = 0.293012, step = 30001 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.258\n",
      "INFO:tensorflow:loss = 0.216568, step = 30101 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.576\n",
      "INFO:tensorflow:loss = 0.0653789, step = 30201 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.023\n",
      "INFO:tensorflow:loss = 0.121085, step = 30301 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.568\n",
      "INFO:tensorflow:loss = 0.247516, step = 30401 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.783\n",
      "INFO:tensorflow:loss = 0.10018, step = 30501 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 209.46\n",
      "INFO:tensorflow:loss = 0.200494, step = 30601 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.343\n",
      "INFO:tensorflow:loss = 0.15404, step = 30701 (0.493 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.085\n",
      "INFO:tensorflow:loss = 0.104712, step = 30801 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.344\n",
      "INFO:tensorflow:loss = 0.0883829, step = 30901 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.026\n",
      "INFO:tensorflow:loss = 0.0928199, step = 31001 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.352\n",
      "INFO:tensorflow:loss = 0.207417, step = 31101 (0.492 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.823\n",
      "INFO:tensorflow:loss = 0.173716, step = 31201 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.632\n",
      "INFO:tensorflow:loss = 0.100411, step = 31301 (0.485 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.28\n",
      "INFO:tensorflow:loss = 0.0878295, step = 31401 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.272\n",
      "INFO:tensorflow:loss = 0.185236, step = 31501 (0.487 sec)\n",
      "INFO:tensorflow:global_step/sec: 196.455\n",
      "INFO:tensorflow:loss = 0.207741, step = 31601 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 195.941\n",
      "INFO:tensorflow:loss = 0.232341, step = 31701 (0.510 sec)\n",
      "INFO:tensorflow:global_step/sec: 195\n",
      "INFO:tensorflow:loss = 0.0809962, step = 31801 (0.512 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.193\n",
      "INFO:tensorflow:loss = 0.217747, step = 31901 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.092\n",
      "INFO:tensorflow:loss = 0.250003, step = 32001 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.502\n",
      "INFO:tensorflow:loss = 0.221748, step = 32101 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 231.823\n",
      "INFO:tensorflow:loss = 0.212081, step = 32201 (0.432 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:loss = 0.0639502, step = 32301 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.899\n",
      "INFO:tensorflow:loss = 0.119813, step = 32401 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.898\n",
      "INFO:tensorflow:loss = 0.11623, step = 32501 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.962\n",
      "INFO:tensorflow:loss = 0.120416, step = 32601 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.706\n",
      "INFO:tensorflow:loss = 0.251687, step = 32701 (0.417 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.37\n",
      "INFO:tensorflow:loss = 0.245373, step = 32801 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.366\n",
      "INFO:tensorflow:loss = 0.137756, step = 32901 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 254.065\n",
      "INFO:tensorflow:loss = 0.107716, step = 33001 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.945\n",
      "INFO:tensorflow:loss = 0.150147, step = 33101 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 253.097\n",
      "INFO:tensorflow:loss = 0.18908, step = 33201 (0.395 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.705\n",
      "INFO:tensorflow:loss = 0.217502, step = 33301 (0.397 sec)\n",
      "INFO:tensorflow:global_step/sec: 229.528\n",
      "INFO:tensorflow:loss = 0.172186, step = 33401 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 247.998\n",
      "INFO:tensorflow:loss = 0.160277, step = 33501 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.246\n",
      "INFO:tensorflow:loss = 0.14805, step = 33601 (0.403 sec)\n",
      "INFO:tensorflow:global_step/sec: 242.445\n",
      "INFO:tensorflow:loss = 0.11059, step = 33701 (0.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 249.631\n",
      "INFO:tensorflow:loss = 0.161149, step = 33801 (0.401 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.042\n",
      "INFO:tensorflow:loss = 0.175642, step = 33901 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.63\n",
      "INFO:tensorflow:loss = 0.132871, step = 34001 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 248.423\n",
      "INFO:tensorflow:loss = 0.115475, step = 34101 (0.402 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.263\n",
      "INFO:tensorflow:loss = 0.20883, step = 34201 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.923\n",
      "INFO:tensorflow:loss = 0.0852439, step = 34301 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 251.563\n",
      "INFO:tensorflow:loss = 0.157904, step = 34401 (0.398 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.186\n",
      "INFO:tensorflow:loss = 0.224993, step = 34501 (0.406 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.922\n",
      "INFO:tensorflow:loss = 0.22797, step = 34601 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.282\n",
      "INFO:tensorflow:loss = 0.134234, step = 34701 (0.411 sec)\n",
      "INFO:tensorflow:global_step/sec: 246.651\n",
      "INFO:tensorflow:loss = 0.056402, step = 34801 (0.405 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.115\n",
      "INFO:tensorflow:loss = 0.156078, step = 34901 (0.408 sec)\n",
      "INFO:tensorflow:global_step/sec: 241.535\n",
      "INFO:tensorflow:loss = 0.166242, step = 35001 (0.415 sec)\n",
      "INFO:tensorflow:global_step/sec: 243.098\n",
      "INFO:tensorflow:loss = 0.206267, step = 35101 (0.410 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.101\n",
      "INFO:tensorflow:loss = 0.104347, step = 35201 (0.507 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.144\n",
      "INFO:tensorflow:loss = 0.181363, step = 35301 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.12\n",
      "INFO:tensorflow:loss = 0.13404, step = 35401 (0.501 sec)\n",
      "INFO:tensorflow:global_step/sec: 203.536\n",
      "INFO:tensorflow:loss = 0.300956, step = 35501 (0.491 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.723\n",
      "INFO:tensorflow:loss = 0.132206, step = 35601 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.966\n",
      "INFO:tensorflow:loss = 0.0876101, step = 35701 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.085\n",
      "INFO:tensorflow:loss = 0.219042, step = 35801 (0.483 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.661\n",
      "INFO:tensorflow:loss = 0.173877, step = 35901 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.761\n",
      "INFO:tensorflow:loss = 0.143817, step = 36001 (0.488 sec)\n",
      "INFO:tensorflow:global_step/sec: 230.016\n",
      "INFO:tensorflow:loss = 0.181125, step = 36101 (0.436 sec)\n",
      "INFO:tensorflow:global_step/sec: 193.777\n",
      "INFO:tensorflow:loss = 0.148521, step = 36201 (0.515 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.855\n",
      "INFO:tensorflow:loss = 0.189688, step = 36301 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.256\n",
      "INFO:tensorflow:loss = 0.0634098, step = 36401 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 197.85\n",
      "INFO:tensorflow:loss = 0.0885845, step = 36501 (0.505 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.421\n",
      "INFO:tensorflow:loss = 0.154401, step = 36601 (0.489 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.899\n",
      "INFO:tensorflow:loss = 0.285804, step = 36701 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.046\n",
      "INFO:tensorflow:loss = 0.26474, step = 36801 (0.481 sec)\n",
      "INFO:tensorflow:global_step/sec: 177.312\n",
      "INFO:tensorflow:loss = 0.149422, step = 36901 (0.564 sec)\n",
      "INFO:tensorflow:global_step/sec: 207.613\n",
      "INFO:tensorflow:loss = 0.217727, step = 37001 (0.482 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.78\n",
      "INFO:tensorflow:loss = 0.0651335, step = 37101 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 211.261\n",
      "INFO:tensorflow:loss = 0.0910484, step = 37201 (0.473 sec)\n",
      "INFO:tensorflow:global_step/sec: 201.543\n",
      "INFO:tensorflow:loss = 0.201141, step = 37301 (0.496 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.702\n",
      "INFO:tensorflow:loss = 0.100025, step = 37401 (0.479 sec)\n",
      "INFO:tensorflow:global_step/sec: 208.222\n",
      "INFO:tensorflow:loss = 0.0926015, step = 37501 (0.480 sec)\n",
      "INFO:tensorflow:global_step/sec: 206.362\n",
      "INFO:tensorflow:loss = 0.108801, step = 37601 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 220.015\n",
      "INFO:tensorflow:loss = 0.0923419, step = 37701 (0.457 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.108\n",
      "INFO:tensorflow:loss = 0.183337, step = 37801 (0.503 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.648\n",
      "INFO:tensorflow:loss = 0.225875, step = 37901 (0.495 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.011\n",
      "INFO:tensorflow:loss = 0.167673, step = 38001 (0.490 sec)\n",
      "INFO:tensorflow:global_step/sec: 202.204\n",
      "INFO:tensorflow:loss = 0.0713817, step = 38101 (0.494 sec)\n",
      "INFO:tensorflow:global_step/sec: 200.852\n",
      "INFO:tensorflow:loss = 0.181318, step = 38201 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 204.814\n",
      "INFO:tensorflow:loss = 0.120197, step = 38301 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.889\n",
      "INFO:tensorflow:loss = 0.0879337, step = 38401 (0.486 sec)\n",
      "INFO:tensorflow:global_step/sec: 199.86\n",
      "INFO:tensorflow:loss = 0.139518, step = 38501 (0.500 sec)\n",
      "INFO:tensorflow:global_step/sec: 198.333\n",
      "INFO:tensorflow:loss = 0.100345, step = 38601 (0.506 sec)\n",
      "INFO:tensorflow:global_step/sec: 205.841\n",
      "INFO:tensorflow:loss = 0.122685, step = 38701 (0.484 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.366\n",
      "INFO:tensorflow:loss = 0.10157, step = 38801 (0.425 sec)\n",
      "INFO:tensorflow:global_step/sec: 240.512\n",
      "INFO:tensorflow:loss = 0.0809093, step = 38901 (0.416 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.356\n",
      "INFO:tensorflow:loss = 0.117047, step = 39001 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 236.121\n",
      "INFO:tensorflow:loss = 0.198177, step = 39101 (0.423 sec)\n",
      "INFO:tensorflow:global_step/sec: 237.005\n",
      "INFO:tensorflow:loss = 0.158239, step = 39201 (0.422 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.331\n",
      "INFO:tensorflow:loss = 0.113698, step = 39301 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 235.735\n",
      "INFO:tensorflow:loss = 0.0855179, step = 39401 (0.424 sec)\n",
      "INFO:tensorflow:global_step/sec: 244.594\n",
      "INFO:tensorflow:loss = 0.0924429, step = 39501 (0.409 sec)\n",
      "INFO:tensorflow:global_step/sec: 233.792\n",
      "INFO:tensorflow:loss = 0.0682304, step = 39601 (0.428 sec)\n",
      "INFO:tensorflow:global_step/sec: 245.433\n",
      "INFO:tensorflow:loss = 0.0745502, step = 39701 (0.407 sec)\n",
      "INFO:tensorflow:global_step/sec: 239.738\n",
      "INFO:tensorflow:loss = 0.162362, step = 39801 (0.418 sec)\n",
      "INFO:tensorflow:global_step/sec: 228.204\n",
      "INFO:tensorflow:loss = 0.0676468, step = 39901 (0.437 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 40000 into /tmp/tmphfUNpl/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 0.113743.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SKCompat()"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "config = tf.contrib.learn.RunConfig(tf_random_seed = 42)\n",
    "\n",
    "feature_cols = tf.contrib.learn.infer_real_valued_columns_from_input(X_train)\n",
    "dnn_clf = tf.contrib.learn.DNNClassifier(hidden_units=[300,300,300], n_classes = 10,\n",
    "                                        feature_columns = feature_cols)\n",
    "dnn_clf = tf.contrib.learn.SKCompat(dnn_clf)\n",
    "dnn_clf.fit(X_train,y_train,batch_size = 50 , steps = 40000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmphfUNpl/model.ckpt-40000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.78212290502793291"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_for =dnn_clf.predict(X_test)\n",
    "accuracy_score(y_test,pred_for['classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:float64 is not supported by many models, consider casting to float32.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/tmphfUNpl/model.ckpt-40000\n"
     ]
    }
   ],
   "source": [
    "predict = dnn_clf.predict(titanic_test)\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": load_housing_data(path = \"test.csv\")[\"PassengerId\"],\n",
    "        \"Survived\": predict['classes']\n",
    "    })\n",
    "csv_path = os.path.join(HOUSING_PATH, \"submission_dnn.csv\")\n",
    "submission.to_csv(csv_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin\n",
      "0 :epoch\n",
      "0 error:  0.219244137078\n",
      "1 :epoch\n",
      "1 error:  0.177013236137\n",
      "2 :epoch\n",
      "2 error:  0.162284039595\n",
      "3 :epoch\n",
      "3 error:  0.152602073455\n",
      "4 :epoch\n",
      "4 error:  0.147741998657\n",
      "5 :epoch\n",
      "5 error:  0.141745581506\n",
      "6 :epoch\n",
      "7 :epoch\n",
      "8 :epoch\n",
      "8 error:  0.139288834164\n",
      "9 :epoch\n",
      "10 :epoch\n",
      "10 error:  0.138549131505\n",
      "11 :epoch\n",
      "12 :epoch\n",
      "13 :epoch\n",
      "14 :epoch\n",
      "14 error:  0.137965963899\n",
      "15 :epoch\n",
      "16 :epoch\n",
      "17 :epoch\n",
      "18 :epoch\n",
      "19 :epoch\n",
      "20 :epoch\n",
      "21 :epoch\n",
      "21 error:  0.137365787881\n",
      "22 :epoch\n",
      "23 :epoch\n",
      "24 :epoch\n",
      "24 error:  0.137060022227\n",
      "25 :epoch\n",
      "26 :epoch\n",
      "27 :epoch\n",
      "28 :epoch\n",
      "29 :epoch\n",
      "30 :epoch\n",
      "31 :epoch\n",
      "32 :epoch\n",
      "33 :epoch\n",
      "34 :epoch\n",
      "35 :epoch\n",
      "36 :epoch\n",
      "37 :epoch\n",
      "38 :epoch\n",
      "39 :epoch\n",
      "40 :epoch\n",
      "41 :epoch\n",
      "42 :epoch\n",
      "43 :epoch\n",
      "44 :epoch\n",
      "44 error:  0.136644225158\n",
      "45 :epoch\n",
      "46 :epoch\n",
      "47 :epoch\n",
      "48 :epoch\n",
      "48 error:  0.136148832591\n",
      "49 :epoch\n",
      "50 :epoch\n",
      "51 :epoch\n",
      "52 :epoch\n",
      "53 :epoch\n",
      "54 :epoch\n",
      "55 :epoch\n",
      "56 :epoch\n",
      "57 :epoch\n",
      "58 :epoch\n",
      "59 :epoch\n",
      "60 :epoch\n",
      "60 error:  0.136052433153\n",
      "61 :epoch\n",
      "62 :epoch\n",
      "63 :epoch\n",
      "64 :epoch\n",
      "65 :epoch\n",
      "66 :epoch\n",
      "67 :epoch\n",
      "68 :epoch\n",
      "69 :epoch\n",
      "70 :epoch\n",
      "71 :epoch\n",
      "72 :epoch\n",
      "73 :epoch\n",
      "74 :epoch\n",
      "74 error:  0.135137828007\n",
      "75 :epoch\n",
      "76 :epoch\n",
      "77 :epoch\n",
      "78 :epoch\n",
      "79 :epoch\n",
      "80 :epoch\n",
      "81 :epoch\n",
      "82 :epoch\n",
      "83 :epoch\n",
      "84 :epoch\n",
      "85 :epoch\n",
      "86 :epoch\n",
      "87 :epoch\n",
      "88 :epoch\n",
      "89 :epoch\n",
      "90 :epoch\n",
      "91 :epoch\n",
      "92 :epoch\n",
      "93 :epoch\n",
      "94 :epoch\n",
      "95 :epoch\n",
      "96 :epoch\n",
      "97 :epoch\n",
      "98 :epoch\n",
      "99 :epoch\n",
      "100 :epoch\n",
      "101 :epoch\n",
      "102 :epoch\n",
      "103 :epoch\n",
      "104 :epoch\n",
      "105 :epoch\n",
      "106 :epoch\n",
      "107 :epoch\n",
      "108 :epoch\n",
      "109 :epoch\n",
      "110 :epoch\n",
      "111 :epoch\n",
      "112 :epoch\n",
      "113 :epoch\n",
      "114 :epoch\n",
      "115 :epoch\n",
      "116 :epoch\n",
      "117 :epoch\n",
      "118 :epoch\n",
      "119 :epoch\n",
      "120 :epoch\n",
      "121 :epoch\n",
      "122 :epoch\n",
      "123 :epoch\n",
      "124 :epoch\n",
      "125 :epoch\n",
      "126 :epoch\n",
      "127 :epoch\n",
      "128 :epoch\n",
      "129 :epoch\n",
      "130 :epoch\n",
      "131 :epoch\n",
      "132 :epoch\n",
      "133 :epoch\n",
      "134 :epoch\n",
      "135 :epoch\n",
      "136 :epoch\n",
      "137 :epoch\n",
      "138 :epoch\n",
      "139 :epoch\n",
      "140 :epoch\n",
      "141 :epoch\n",
      "142 :epoch\n",
      "143 :epoch\n",
      "144 :epoch\n",
      "145 :epoch\n",
      "146 :epoch\n",
      "147 :epoch\n",
      "148 :epoch\n",
      "149 :epoch\n",
      "150 :epoch\n",
      "151 :epoch\n",
      "152 :epoch\n",
      "153 :epoch\n",
      "154 :epoch\n",
      "155 :epoch\n",
      "156 :epoch\n",
      "157 :epoch\n",
      "158 :epoch\n",
      "159 :epoch\n",
      "160 :epoch\n",
      "161 :epoch\n",
      "162 :epoch\n",
      "163 :epoch\n",
      "164 :epoch\n",
      "165 :epoch\n",
      "166 :epoch\n",
      "167 :epoch\n",
      "168 :epoch\n",
      "169 :epoch\n",
      "170 :epoch\n",
      "171 :epoch\n",
      "172 :epoch\n",
      "173 :epoch\n",
      "174 :epoch\n",
      "175 :epoch\n",
      "176 :epoch\n",
      "177 :epoch\n",
      "178 :epoch\n",
      "179 :epoch\n",
      "180 :epoch\n",
      "181 :epoch\n",
      "182 :epoch\n",
      "183 :epoch\n",
      "184 :epoch\n",
      "185 :epoch\n",
      "186 :epoch\n",
      "187 :epoch\n",
      "188 :epoch\n",
      "189 :epoch\n",
      "190 :epoch\n",
      "191 :epoch\n",
      "192 :epoch\n",
      "193 :epoch\n",
      "194 :epoch\n",
      "195 :epoch\n",
      "196 :epoch\n",
      "197 :epoch\n",
      "198 :epoch\n",
      "199 :epoch\n",
      "200 :epoch\n",
      "201 :epoch\n",
      "202 :epoch\n",
      "203 :epoch\n",
      "204 :epoch\n",
      "205 :epoch\n",
      "206 :epoch\n",
      "207 :epoch\n",
      "208 :epoch\n",
      "209 :epoch\n",
      "210 :epoch\n",
      "211 :epoch\n",
      "212 :epoch\n",
      "213 :epoch\n",
      "214 :epoch\n",
      "215 :epoch\n",
      "216 :epoch\n",
      "217 :epoch\n",
      "218 :epoch\n",
      "219 :epoch\n",
      "220 :epoch\n",
      "221 :epoch\n",
      "222 :epoch\n",
      "223 :epoch\n",
      "224 :epoch\n",
      "225 :epoch\n",
      "226 :epoch\n",
      "227 :epoch\n",
      "228 :epoch\n",
      "229 :epoch\n",
      "230 :epoch\n",
      "231 :epoch\n",
      "232 :epoch\n",
      "233 :epoch\n",
      "234 :epoch\n",
      "235 :epoch\n",
      "236 :epoch\n",
      "237 :epoch\n",
      "238 :epoch\n",
      "239 :epoch\n",
      "240 :epoch\n",
      "241 :epoch\n",
      "242 :epoch\n",
      "243 :epoch\n",
      "244 :epoch\n",
      "245 :epoch\n",
      "246 :epoch\n",
      "247 :epoch\n",
      "248 :epoch\n",
      "249 :epoch\n",
      "250 :epoch\n",
      "251 :epoch\n",
      "252 :epoch\n",
      "253 :epoch\n",
      "254 :epoch\n",
      "255 :epoch\n",
      "256 :epoch\n",
      "257 :epoch\n",
      "258 :epoch\n",
      "259 :epoch\n",
      "260 :epoch\n",
      "261 :epoch\n",
      "262 :epoch\n",
      "263 :epoch\n",
      "264 :epoch\n",
      "265 :epoch\n",
      "266 :epoch\n",
      "267 :epoch\n",
      "268 :epoch\n",
      "269 :epoch\n",
      "270 :epoch\n",
      "271 :epoch\n",
      "272 :epoch\n",
      "273 :epoch\n",
      "274 :epoch\n",
      "275 :epoch\n",
      "276 :epoch\n",
      "277 :epoch\n",
      "278 :epoch\n",
      "279 :epoch\n",
      "280 :epoch\n",
      "281 :epoch\n",
      "282 :epoch\n",
      "283 :epoch\n",
      "284 :epoch\n",
      "285 :epoch\n",
      "286 :epoch\n",
      "287 :epoch\n",
      "288 :epoch\n",
      "289 :epoch\n",
      "290 :epoch\n",
      "291 :epoch\n",
      "292 :epoch\n",
      "293 :epoch\n",
      "294 :epoch\n",
      "295 :epoch\n",
      "296 :epoch\n",
      "297 :epoch\n",
      "298 :epoch\n",
      "299 :epoch\n",
      "300 :epoch\n",
      "301 :epoch\n",
      "302 :epoch\n",
      "303 :epoch\n",
      "304 :epoch\n",
      "305 :epoch\n",
      "306 :epoch\n",
      "307 :epoch\n",
      "308 :epoch\n",
      "309 :epoch\n",
      "310 :epoch\n",
      "311 :epoch\n",
      "312 :epoch\n",
      "313 :epoch\n",
      "314 :epoch\n",
      "315 :epoch\n",
      "316 :epoch\n",
      "317 :epoch\n",
      "318 :epoch\n",
      "319 :epoch\n",
      "320 :epoch\n",
      "321 :epoch\n",
      "322 :epoch\n",
      "323 :epoch\n",
      "324 :epoch\n",
      "325 :epoch\n",
      "326 :epoch\n",
      "327 :epoch\n",
      "328 :epoch\n",
      "329 :epoch\n",
      "330 :epoch\n",
      "331 :epoch\n",
      "332 :epoch\n",
      "333 :epoch\n",
      "334 :epoch\n",
      "335 :epoch\n",
      "336 :epoch\n",
      "337 :epoch\n",
      "338 :epoch\n",
      "339 :epoch\n",
      "340 :epoch\n",
      "341 :epoch\n",
      "342 :epoch\n",
      "343 :epoch\n",
      "344 :epoch\n",
      "345 :epoch\n",
      "346 :epoch\n",
      "347 :epoch\n",
      "348 :epoch\n",
      "349 :epoch\n",
      "350 :epoch\n",
      "351 :epoch\n",
      "352 :epoch\n",
      "353 :epoch\n",
      "354 :epoch\n",
      "355 :epoch\n",
      "356 :epoch\n",
      "357 :epoch\n",
      "358 :epoch\n",
      "359 :epoch\n",
      "360 :epoch\n",
      "361 :epoch\n",
      "362 :epoch\n",
      "363 :epoch\n",
      "364 :epoch\n",
      "365 :epoch\n",
      "366 :epoch\n",
      "367 :epoch\n",
      "368 :epoch\n",
      "369 :epoch\n",
      "370 :epoch\n",
      "371 :epoch\n",
      "372 :epoch\n",
      "373 :epoch\n",
      "374 :epoch\n",
      "375 :epoch\n",
      "376 :epoch\n",
      "377 :epoch\n",
      "378 :epoch\n",
      "379 :epoch\n",
      "380 :epoch\n",
      "381 :epoch\n",
      "382 :epoch\n",
      "383 :epoch\n",
      "384 :epoch\n",
      "385 :epoch\n",
      "386 :epoch\n",
      "387 :epoch\n",
      "388 :epoch\n",
      "389 :epoch\n",
      "390 :epoch\n",
      "391 :epoch\n",
      "392 :epoch\n",
      "393 :epoch\n",
      "394 :epoch\n",
      "395 :epoch\n",
      "396 :epoch\n",
      "397 :epoch\n",
      "398 :epoch\n",
      "399 :epoch\n",
      "400 :epoch\n",
      "401 :epoch\n",
      "402 :epoch\n",
      "403 :epoch\n",
      "404 :epoch\n",
      "405 :epoch\n",
      "406 :epoch\n",
      "407 :epoch\n",
      "408 :epoch\n",
      "409 :epoch\n",
      "410 :epoch\n",
      "411 :epoch\n",
      "412 :epoch\n",
      "413 :epoch\n",
      "414 :epoch\n",
      "415 :epoch\n",
      "416 :epoch\n",
      "417 :epoch\n",
      "418 :epoch\n",
      "419 :epoch\n",
      "420 :epoch\n",
      "421 :epoch\n",
      "422 :epoch\n",
      "423 :epoch\n",
      "424 :epoch\n",
      "425 :epoch\n",
      "426 :epoch\n",
      "427 :epoch\n",
      "428 :epoch\n",
      "429 :epoch\n",
      "430 :epoch\n",
      "431 :epoch\n",
      "432 :epoch\n",
      "433 :epoch\n",
      "434 :epoch\n",
      "435 :epoch\n",
      "436 :epoch\n",
      "437 :epoch\n",
      "438 :epoch\n",
      "439 :epoch\n",
      "440 :epoch\n",
      "441 :epoch\n",
      "442 :epoch\n",
      "443 :epoch\n",
      "444 :epoch\n",
      "445 :epoch\n",
      "446 :epoch\n",
      "447 :epoch\n",
      "448 :epoch\n",
      "449 :epoch\n",
      "450 :epoch\n",
      "451 :epoch\n",
      "452 :epoch\n",
      "453 :epoch\n",
      "454 :epoch\n",
      "455 :epoch\n",
      "456 :epoch\n",
      "457 :epoch\n",
      "458 :epoch\n",
      "459 :epoch\n",
      "460 :epoch\n",
      "461 :epoch\n",
      "462 :epoch\n",
      "463 :epoch\n",
      "464 :epoch\n",
      "465 :epoch\n",
      "466 :epoch\n",
      "467 :epoch\n",
      "468 :epoch\n",
      "469 :epoch\n",
      "470 :epoch\n",
      "471 :epoch\n",
      "472 :epoch\n",
      "473 :epoch\n",
      "474 :epoch\n",
      "475 :epoch\n",
      "476 :epoch\n",
      "477 :epoch\n",
      "478 :epoch\n",
      "479 :epoch\n",
      "480 :epoch\n",
      "481 :epoch\n",
      "482 :epoch\n",
      "483 :epoch\n",
      "484 :epoch\n",
      "485 :epoch\n",
      "486 :epoch\n",
      "487 :epoch\n",
      "488 :epoch\n",
      "489 :epoch\n",
      "490 :epoch\n",
      "491 :epoch\n",
      "492 :epoch\n",
      "493 :epoch\n",
      "494 :epoch\n",
      "495 :epoch\n",
      "496 :epoch\n",
      "497 :epoch\n",
      "498 :epoch\n",
      "499 :epoch\n",
      "500 :epoch\n",
      "501 :epoch\n",
      "502 :epoch\n",
      "503 :epoch\n",
      "504 :epoch\n",
      "505 :epoch\n",
      "506 :epoch\n",
      "507 :epoch\n",
      "508 :epoch\n",
      "509 :epoch\n",
      "510 :epoch\n",
      "511 :epoch\n",
      "512 :epoch\n",
      "513 :epoch\n",
      "514 :epoch\n",
      "515 :epoch\n",
      "516 :epoch\n",
      "517 :epoch\n",
      "518 :epoch\n",
      "519 :epoch\n",
      "520 :epoch\n",
      "521 :epoch\n",
      "522 :epoch\n",
      "523 :epoch\n",
      "524 :epoch\n",
      "525 :epoch\n",
      "526 :epoch\n",
      "527 :epoch\n",
      "528 :epoch\n",
      "529 :epoch\n",
      "530 :epoch\n",
      "531 :epoch\n",
      "532 :epoch\n",
      "533 :epoch\n",
      "534 :epoch\n",
      "535 :epoch\n",
      "536 :epoch\n",
      "537 :epoch\n",
      "538 :epoch\n",
      "539 :epoch\n",
      "540 :epoch\n",
      "541 :epoch\n",
      "542 :epoch\n",
      "543 :epoch\n",
      "544 :epoch\n",
      "545 :epoch\n",
      "546 :epoch\n",
      "547 :epoch\n",
      "548 :epoch\n",
      "549 :epoch\n",
      "550 :epoch\n",
      "551 :epoch\n",
      "552 :epoch\n",
      "553 :epoch\n",
      "554 :epoch\n",
      "555 :epoch\n",
      "556 :epoch\n",
      "557 :epoch\n",
      "558 :epoch\n",
      "559 :epoch\n",
      "560 :epoch\n",
      "561 :epoch\n",
      "562 :epoch\n",
      "563 :epoch\n",
      "564 :epoch\n",
      "565 :epoch\n",
      "566 :epoch\n",
      "567 :epoch\n",
      "568 :epoch\n",
      "569 :epoch\n",
      "570 :epoch\n",
      "571 :epoch\n",
      "572 :epoch\n",
      "573 :epoch\n",
      "574 :epoch\n",
      "575 :epoch\n",
      "576 :epoch\n",
      "577 :epoch\n",
      "578 :epoch\n",
      "579 :epoch\n",
      "580 :epoch\n",
      "581 :epoch\n",
      "582 :epoch\n",
      "583 :epoch\n",
      "584 :epoch\n",
      "585 :epoch\n",
      "586 :epoch\n",
      "587 :epoch\n",
      "588 :epoch\n",
      "589 :epoch\n",
      "590 :epoch\n",
      "591 :epoch\n",
      "592 :epoch\n",
      "593 :epoch\n",
      "594 :epoch\n",
      "595 :epoch\n",
      "596 :epoch\n",
      "597 :epoch\n",
      "598 :epoch\n",
      "599 :epoch\n",
      "600 :epoch\n",
      "601 :epoch\n",
      "602 :epoch\n",
      "603 :epoch\n",
      "604 :epoch\n",
      "605 :epoch\n",
      "606 :epoch\n",
      "607 :epoch\n",
      "608 :epoch\n",
      "609 :epoch\n",
      "610 :epoch\n",
      "611 :epoch\n",
      "612 :epoch\n",
      "613 :epoch\n",
      "614 :epoch\n",
      "615 :epoch\n",
      "616 :epoch\n",
      "617 :epoch\n",
      "618 :epoch\n",
      "619 :epoch\n",
      "620 :epoch\n",
      "621 :epoch\n",
      "622 :epoch\n",
      "623 :epoch\n",
      "624 :epoch\n",
      "625 :epoch\n",
      "626 :epoch\n",
      "627 :epoch\n",
      "628 :epoch\n",
      "629 :epoch\n",
      "630 :epoch\n",
      "631 :epoch\n",
      "632 :epoch\n",
      "633 :epoch\n",
      "634 :epoch\n",
      "635 :epoch\n",
      "636 :epoch\n",
      "637 :epoch\n",
      "638 :epoch\n",
      "639 :epoch\n",
      "640 :epoch\n",
      "641 :epoch\n",
      "642 :epoch\n",
      "643 :epoch\n",
      "644 :epoch\n",
      "645 :epoch\n",
      "646 :epoch\n",
      "647 :epoch\n",
      "648 :epoch\n",
      "649 :epoch\n",
      "650 :epoch\n",
      "651 :epoch\n",
      "652 :epoch\n",
      "653 :epoch\n",
      "654 :epoch\n",
      "655 :epoch\n",
      "656 :epoch\n",
      "657 :epoch\n",
      "658 :epoch\n",
      "659 :epoch\n",
      "660 :epoch\n",
      "661 :epoch\n",
      "662 :epoch\n",
      "663 :epoch\n",
      "664 :epoch\n",
      "665 :epoch\n",
      "666 :epoch\n",
      "667 :epoch\n",
      "668 :epoch\n",
      "669 :epoch\n",
      "670 :epoch\n",
      "671 :epoch\n",
      "672 :epoch\n",
      "673 :epoch\n",
      "674 :epoch\n",
      "675 :epoch\n",
      "676 :epoch\n",
      "677 :epoch\n",
      "678 :epoch\n",
      "679 :epoch\n",
      "680 :epoch\n",
      "681 :epoch\n",
      "682 :epoch\n",
      "683 :epoch\n",
      "684 :epoch\n",
      "685 :epoch\n",
      "686 :epoch\n",
      "687 :epoch\n",
      "688 :epoch\n",
      "689 :epoch\n",
      "690 :epoch\n",
      "691 :epoch\n",
      "692 :epoch\n",
      "693 :epoch\n",
      "694 :epoch\n",
      "695 :epoch\n",
      "696 :epoch\n",
      "697 :epoch\n",
      "698 :epoch\n",
      "699 :epoch\n",
      "700 :epoch\n",
      "701 :epoch\n",
      "702 :epoch\n",
      "703 :epoch\n",
      "704 :epoch\n",
      "705 :epoch\n",
      "706 :epoch\n",
      "707 :epoch\n",
      "708 :epoch\n",
      "709 :epoch\n",
      "710 :epoch\n",
      "711 :epoch\n",
      "712 :epoch\n",
      "713 :epoch\n",
      "714 :epoch\n",
      "715 :epoch\n",
      "716 :epoch\n",
      "717 :epoch\n",
      "718 :epoch\n",
      "719 :epoch\n",
      "720 :epoch\n",
      "721 :epoch\n",
      "722 :epoch\n",
      "723 :epoch\n",
      "724 :epoch\n",
      "725 :epoch\n",
      "726 :epoch\n",
      "727 :epoch\n",
      "728 :epoch\n",
      "729 :epoch\n",
      "730 :epoch\n",
      "731 :epoch\n",
      "732 :epoch\n",
      "733 :epoch\n",
      "734 :epoch\n",
      "735 :epoch\n",
      "736 :epoch\n",
      "737 :epoch\n",
      "738 :epoch\n",
      "739 :epoch\n",
      "740 :epoch\n",
      "741 :epoch\n",
      "742 :epoch\n",
      "743 :epoch\n",
      "744 :epoch\n",
      "745 :epoch\n",
      "746 :epoch\n",
      "747 :epoch\n",
      "748 :epoch\n",
      "749 :epoch\n",
      "750 :epoch\n",
      "751 :epoch\n",
      "752 :epoch\n",
      "753 :epoch\n",
      "754 :epoch\n",
      "755 :epoch\n",
      "756 :epoch\n",
      "757 :epoch\n",
      "758 :epoch\n",
      "759 :epoch\n",
      "760 :epoch\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "761 :epoch\n",
      "762 :epoch\n",
      "763 :epoch\n",
      "764 :epoch\n",
      "765 :epoch\n",
      "766 :epoch\n",
      "767 :epoch\n",
      "768 :epoch\n",
      "769 :epoch\n",
      "770 :epoch\n",
      "771 :epoch\n",
      "772 :epoch\n",
      "773 :epoch\n",
      "774 :epoch\n",
      "775 :epoch\n",
      "776 :epoch\n",
      "777 :epoch\n",
      "778 :epoch\n",
      "779 :epoch\n",
      "780 :epoch\n",
      "781 :epoch\n",
      "782 :epoch\n",
      "783 :epoch\n",
      "784 :epoch\n",
      "785 :epoch\n",
      "786 :epoch\n",
      "787 :epoch\n",
      "788 :epoch\n",
      "789 :epoch\n",
      "790 :epoch\n",
      "791 :epoch\n",
      "792 :epoch\n",
      "793 :epoch\n",
      "794 :epoch\n",
      "795 :epoch\n",
      "796 :epoch\n",
      "797 :epoch\n",
      "798 :epoch\n",
      "799 :epoch\n",
      "800 :epoch\n",
      "801 :epoch\n",
      "802 :epoch\n",
      "803 :epoch\n",
      "804 :epoch\n",
      "805 :epoch\n",
      "806 :epoch\n",
      "807 :epoch\n",
      "808 :epoch\n",
      "809 :epoch\n",
      "810 :epoch\n",
      "811 :epoch\n",
      "812 :epoch\n",
      "813 :epoch\n",
      "814 :epoch\n",
      "815 :epoch\n",
      "816 :epoch\n",
      "817 :epoch\n",
      "818 :epoch\n",
      "819 :epoch\n",
      "820 :epoch\n",
      "821 :epoch\n",
      "822 :epoch\n",
      "823 :epoch\n",
      "824 :epoch\n",
      "825 :epoch\n",
      "826 :epoch\n",
      "827 :epoch\n",
      "828 :epoch\n",
      "829 :epoch\n",
      "830 :epoch\n",
      "831 :epoch\n",
      "832 :epoch\n",
      "833 :epoch\n",
      "834 :epoch\n",
      "835 :epoch\n",
      "836 :epoch\n",
      "837 :epoch\n",
      "838 :epoch\n",
      "839 :epoch\n",
      "840 :epoch\n",
      "841 :epoch\n",
      "842 :epoch\n",
      "843 :epoch\n",
      "844 :epoch\n",
      "845 :epoch\n",
      "846 :epoch\n",
      "847 :epoch\n",
      "848 :epoch\n",
      "849 :epoch\n",
      "850 :epoch\n",
      "851 :epoch\n",
      "852 :epoch\n",
      "853 :epoch\n",
      "854 :epoch\n",
      "855 :epoch\n",
      "856 :epoch\n",
      "857 :epoch\n",
      "858 :epoch\n",
      "859 :epoch\n",
      "860 :epoch\n",
      "861 :epoch\n",
      "862 :epoch\n",
      "863 :epoch\n",
      "864 :epoch\n",
      "865 :epoch\n",
      "866 :epoch\n",
      "867 :epoch\n",
      "868 :epoch\n",
      "869 :epoch\n",
      "870 :epoch\n",
      "871 :epoch\n",
      "872 :epoch\n",
      "873 :epoch\n",
      "874 :epoch\n",
      "875 :epoch\n",
      "876 :epoch\n",
      "877 :epoch\n",
      "878 :epoch\n",
      "879 :epoch\n",
      "880 :epoch\n",
      "881 :epoch\n",
      "882 :epoch\n",
      "883 :epoch\n",
      "884 :epoch\n",
      "885 :epoch\n",
      "886 :epoch\n",
      "887 :epoch\n",
      "888 :epoch\n",
      "889 :epoch\n",
      "890 :epoch\n",
      "891 :epoch\n",
      "892 :epoch\n",
      "893 :epoch\n",
      "894 :epoch\n",
      "895 :epoch\n",
      "896 :epoch\n",
      "897 :epoch\n",
      "898 :epoch\n",
      "899 :epoch\n",
      "900 :epoch\n",
      "901 :epoch\n",
      "902 :epoch\n",
      "903 :epoch\n",
      "904 :epoch\n",
      "905 :epoch\n",
      "906 :epoch\n",
      "907 :epoch\n",
      "908 :epoch\n",
      "909 :epoch\n",
      "910 :epoch\n",
      "911 :epoch\n",
      "912 :epoch\n",
      "913 :epoch\n",
      "914 :epoch\n",
      "915 :epoch\n",
      "916 :epoch\n",
      "917 :epoch\n",
      "918 :epoch\n",
      "919 :epoch\n",
      "920 :epoch\n",
      "921 :epoch\n",
      "922 :epoch\n",
      "923 :epoch\n",
      "924 :epoch\n",
      "925 :epoch\n",
      "926 :epoch\n",
      "927 :epoch\n",
      "928 :epoch\n",
      "929 :epoch\n",
      "930 :epoch\n",
      "931 :epoch\n",
      "932 :epoch\n",
      "933 :epoch\n",
      "934 :epoch\n",
      "935 :epoch\n",
      "936 :epoch\n",
      "937 :epoch\n",
      "938 :epoch\n",
      "939 :epoch\n",
      "940 :epoch\n",
      "941 :epoch\n",
      "942 :epoch\n",
      "943 :epoch\n",
      "944 :epoch\n",
      "945 :epoch\n",
      "946 :epoch\n",
      "947 :epoch\n",
      "948 :epoch\n",
      "949 :epoch\n",
      "950 :epoch\n",
      "951 :epoch\n",
      "952 :epoch\n",
      "953 :epoch\n",
      "954 :epoch\n",
      "955 :epoch\n",
      "956 :epoch\n",
      "957 :epoch\n",
      "958 :epoch\n",
      "959 :epoch\n",
      "960 :epoch\n",
      "961 :epoch\n",
      "962 :epoch\n",
      "963 :epoch\n",
      "964 :epoch\n",
      "965 :epoch\n",
      "966 :epoch\n",
      "967 :epoch\n",
      "968 :epoch\n",
      "969 :epoch\n",
      "970 :epoch\n",
      "971 :epoch\n",
      "972 :epoch\n",
      "973 :epoch\n",
      "974 :epoch\n",
      "975 :epoch\n",
      "976 :epoch\n",
      "977 :epoch\n",
      "978 :epoch\n",
      "979 :epoch\n",
      "980 :epoch\n",
      "981 :epoch\n",
      "982 :epoch\n",
      "983 :epoch\n",
      "984 :epoch\n",
      "985 :epoch\n",
      "986 :epoch\n",
      "987 :epoch\n",
      "988 :epoch\n",
      "989 :epoch\n",
      "990 :epoch\n",
      "991 :epoch\n",
      "992 :epoch\n",
      "993 :epoch\n",
      "994 :epoch\n",
      "995 :epoch\n",
      "996 :epoch\n",
      "997 :epoch\n",
      "998 :epoch\n",
      "999 :epoch\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(74, SGDRegressor(alpha=0.0001, average=False, epsilon=0.1, eta0=0.0005,\n",
       "        fit_intercept=True, l1_ratio=0.15, learning_rate=u'constant',\n",
       "        loss='squared_loss', n_iter=1, penalty=None, power_t=0.25,\n",
       "        random_state=None, shuffle=True, verbose=0, warm_start=True))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import SGDRegressor\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "poly_scaler = Pipeline([\n",
    "        (\"poly_features\", PolynomialFeatures(degree=3, include_bias=False)),\n",
    "        (\"std_scaler\", StandardScaler()),\n",
    "    ])\n",
    "\n",
    "X_train_poly_scaled = poly_scaler.fit_transform(X_train)\n",
    "X_val_poly_scaled = poly_scaler.transform(X_test)\n",
    "\n",
    "from sklearn.base import clone\n",
    "\n",
    "sgd_reg = SGDRegressor(n_iter = 1,penalty = None,learning_rate = \"constant\",eta0 = 0.0005,warm_start = True)\n",
    "\n",
    "min_val_error = float(\"inf\")\n",
    "best_epoch = None\n",
    "best_model = None\n",
    "print('begin')\n",
    "for epoch in range(1000):\n",
    "    print(epoch ,\":epoch\")\n",
    "    sgd_reg.fit(X_train_poly_scaled,y_train)\n",
    "    y_val_predict = sgd_reg.predict(X_val_poly_scaled)\n",
    "    val_error = mean_squared_error(y_val_predict,y_test)\n",
    "    if val_error < min_val_error:\n",
    "        min_val_error = val_error\n",
    "        best_epoch = epoch\n",
    "        print(best_epoch,\"error: \",min_val_error)\n",
    "        best_model = clone(sgd_reg)\n",
    "best_epoch,best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Can't handle mix of binary and continuous",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-55-25b3035c5615>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpred_for\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpred_for\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/samagra/.local/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36maccuracy_score\u001b[0;34m(y_true, y_pred, normalize, sample_weight)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0;31m# Compute accuracy for each possible representation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'multilabel'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0mdiffering_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcount_nonzero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/samagra/.local/lib/python2.7/site-packages/sklearn/metrics/classification.pyc\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     80\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     81\u001b[0m         raise ValueError(\"Can't handle mix of {0} and {1}\"\n\u001b[0;32m---> 82\u001b[0;31m                          \"\".format(type_true, type_pred))\n\u001b[0m\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \u001b[0;31m# We can't have more than one value on y_type => The set is no more needed\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Can't handle mix of binary and continuous"
     ]
    }
   ],
   "source": [
    "best_model.fit(X_train,y_train)\n",
    "pred_for =best_model.predict(X_test)\n",
    "accuracy_score(y_test,pred_for)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
